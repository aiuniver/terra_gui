{
  "Expected list for 'resources' argument to 'xla_launch' Op, not %r.": "Expected list for 'resources' argument to 'xla_launch' Op, not %r.",
  "Expected list for 'Tresults' argument to 'xla_launch' Op, not %r.": "Expected list for 'Tresults' argument to 'xla_launch' Op, not %r.",
  "Gradient computation of graph in xla.compile() is prohibited because it can cause performance degradation.Please move gradient computation inside xla.compile().": "Gradient computation of graph in xla.compile() is prohibited because it can cause performance degradation.Please move gradient computation inside xla.compile().",
  "List argument 'init_value' to 'xla_variadic_reduce' Op with length %d must match length %d of argument 'input'.": "List argument 'init_value' to 'xla_variadic_reduce' Op with length %d must match length %d of argument 'input'.",
  "Tile assignment must be of type np.ndarray": "Tile assignment must be of type np.ndarray",
  "PartialTile assignment must be of type np.ndarray": "PartialTile assignment must be of type np.ndarray",
  "Split dimension was smaller than the required number of splits: shape=%r, dimension=%r, num_devices=%r": "Split dimension was smaller than the required number of splits: shape=%r, dimension=%r, num_devices=%r",
  "Number of tensor split dimensions (%r) is larger than device mesh rank (%r). tensor_split_dims_mapping: %r, device_mesh.shape: %r": "Number of tensor split dimensions (%r) is larger than device mesh rank (%r). tensor_split_dims_mapping: %r, device_mesh.shape: %r",
  "XLA tuple requires sequence of Shape objects as dimensions": "XLA tuple requires sequence of Shape objects as dimensions",
  "Tuple shape has no dimensions. Try tuple_shapes()?": "Tuple shape has no dimensions. Try tuple_shapes()?",
  "tuple_shapes() called on a non-tuple shape": "tuple_shapes() called on a non-tuple shape",
  "Method not implemented!": "Method not implemented!",
  "Input to `AudioMicrofrontend` should have known rank.": "Input to `AudioMicrofrontend` should have known rank.",
  "Unsupported TensorFlow type `{0}` provided for the {1}": "Unsupported TensorFlow type `{0}` provided for the {1}",
  "See console for info.\n%s\n%s\n": "See console for info.\n%s\n%s\n",
  "The `quantized_input_stats` flag must be defined when either `inference_type` flag or `inference_input_type` flag is set to tf.int8 or tf.uint8.": "The `quantized_input_stats` flag must be defined when either `inference_type` flag or `inference_input_type` flag is set to tf.int8 or tf.uint8.",
  "Given component name not found": "Given component name not found",
  "Given subcomponent name not found": "Given subcomponent name not found",
  "component and subcomponent name don't match": "component and subcomponent name don't match",
  "No '{}' in the SavedModel's SignatureDefs. Possible values are '{}'.": "No '{}' in the SavedModel's SignatureDefs. Possible values are '{}'.",
  "Specify either signature_def_tensor_names or user_tensor_names": "Specify either signature_def_tensor_names or user_tensor_names",
  "SavedModels with assets/ directory are not supported.": "SavedModels with assets/ directory are not supported.",
  "Delegates are currently only supported into CPython' due to missing immediate reference counting.": "Delegates are currently only supported into CPython' due to missing immediate reference counting.",
  "Failed to load delegate from {} {}": "Failed to load delegate from {} {}",
  "None interpreter provided.": "None interpreter provided.",
  "None signature_def_name provided.": "None signature_def_name provided.",
  "Invalid signature_def_name provided.": "Invalid signature_def_name provided.",
  "Invalid number of inputs provided for running a SignatureDef, expected %s vs provided %s": "Invalid number of inputs provided for running a SignatureDef, expected %s vs provided %s",
  "Invalid Input name (%s) for SignatureDef": "Invalid Input name (%s) for SignatureDef",
  "Unrecognized passed in op resolver type: {}": "Unrecognized passed in op resolver type: {}",
  "Failed to open {}": "Failed to open {}",
  "`model_path` or `model_content` must be specified.": "`model_path` or `model_content` must be specified.",
  "Can't both provide `model_path` and `model_content`": "Can't both provide `model_path` and `model_content`",
  "type of num_threads should be int": "type of num_threads should be int",
  "num_threads should >= 1": "num_threads should >= 1",
  "There is at least 1 reference to internal data in the interpreter in the form of a numpy array or slice. Be sure to only hold the function returned from tensor() if you are using raw data access.": "There is at least 1 reference to internal data in the interpreter in the form of a numpy array or slice. Be sure to only hold the function returned from tensor() if you are using raw data access.",
  "Could not get tensor details": "Could not get tensor details",
  "SignatureDef method_name is None and model has {0} Signatures. None is only allowed when the model has 1 SignatureDef": "SignatureDef method_name is None and model has {0} Signatures. None is only allowed when the model has 1 SignatureDef",
  "This Interpreter doesnt handle multiple signatures properly. Proper support is coming soon.": "This Interpreter doesnt handle multiple signatures properly. Proper support is coming soon.",
  "TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.": "TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.",
  "Provide an input generator for representative_dataset": "Provide an input generator for representative_dataset",
  "representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.": "representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.",
  "SavedModel file format({0}) is not supported": "SavedModel file format({0}) is not supported",
  "Please use 'experimental_new_quantizer' instead.": "Please use 'experimental_new_quantizer' instead.",
  "The inference_input_type and inference_output_type must be in {}.": "The inference_input_type and inference_output_type must be in {}.",
  "The inference_input_type and inference_output_type must be tf.float32.": "The inference_input_type and inference_output_type must be tf.float32.",
  "None is only supported in the 1st dimension. Tensor '{0}' has invalid shape '{1}'.": "None is only supported in the 1st dimension. Tensor '{0}' has invalid shape '{1}'.",
  "No ConcreteFunction is specified.": "No ConcreteFunction is specified.",
  "This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.": "This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.",
  "Only support a single signature key.": "Only support a single signature key.",
  "Only support at least one signature key.": "Only support at least one signature key.",
  "Invalid signature key '{}' found. Valid keys are '{}'.": "Invalid signature key '{}' found. Valid keys are '{}'.",
  "The `quantized_input_stats` flag must be defined when either `inference_type` flag or `inference_input_type` flag is set to tf.int8 or tf.uint8. Currently, `inference_type={}` and `inference_input_type={}`.": "The `quantized_input_stats` flag must be defined when either `inference_type` flag or `inference_input_type` flag is set to tf.int8 or tf.uint8. Currently, `inference_type={}` and `inference_input_type={}`.",
  "Provide an input shape for input array '{0}'.": "Provide an input shape for input array '{0}'.",
  "Quantization input stats are not available for input tensors '{0}'.": "Quantization input stats are not available for input tensors '{0}'.",
  "The batch size cannot be set for this model. Please use input_shapes parameter.": "The batch size cannot be set for this model. Please use input_shapes parameter.",
  "`input_arrays` and `output_arrays` are unsupported with Eager mode. If your model requires any of these parameters, please use disable_eager_execution().": "`input_arrays` and `output_arrays` are unsupported with Eager mode. If your model requires any of these parameters, please use disable_eager_execution().",
  "If input_tensors and output_tensors are None, both input_arrays_with_shape and output_arrays|control_output_arrays must be defined.": "If input_tensors and output_tensors are None, both input_arrays_with_shape and output_arrays|control_output_arrays must be defined.",
  "File '{0}' does not exist.": "File '{0}' does not exist.",
  "Unable to parse input file '{}'.": "Unable to parse input file '{}'.",
  "Please freeze the graph using freeze_graph.py.": "Please freeze the graph using freeze_graph.py.",
  "input_shapes must be defined for this model.": "input_shapes must be defined for this model.",
  "input_shapes must contain a value for each item in input_array.": "input_shapes must contain a value for each item in input_array.",
  "Index %d was already used by another call to add": "Index %d was already used by another call to add",
  "You must specify `tag` if using aggregate.": "You must specify `tag` if using aggregate.",
  "You must specify `aggregate` if using tag.": "You must specify `aggregate` if using tag.",
  "Tag %r was called with two indices %r and %r": "Tag %r was called with two indices %r and %r",
  "Unimplemented abstract method.": "Unimplemented abstract method.",
  "Aggregate was missing argument.": "Aggregate was missing argument.",
  "Invalid aggregation type %r specified": "Invalid aggregation type %r specified",
  "Node %s uses input %s not in input_nodes.": "Node %s uses input %s not in input_nodes.",
  "Provide only one of session and graph_def.": "Provide only one of session and graph_def.",
  "Must provide the graph_def.": "Must provide the graph_def.",
  "Must specify session or graph_def as input.": "Must specify session or graph_def as input.",
  "Unsupported value for `{}` flag. Expected FLOAT, INT8, UINT8, or QUANTIZED_UINT8 instead got {}.": "Unsupported value for `{}` flag. Expected FLOAT, INT8, UINT8, or QUANTIZED_UINT8 instead got {}.",
  "This parser only supports nargs='?' (0 or 1 additional arguments)": "This parser only supports nargs='?' (0 or 1 additional arguments)",
  "Invalid argument to --{}. Must use flag alone, or specify true/false.": "Invalid argument to --{}. Must use flag alone, or specify true/false.",
  "--graph_def_file, --saved_model_dir, or --keras_model_file must be specified.": "--graph_def_file, --saved_model_dir, or --keras_model_file must be specified.",
  "Mismatching --input_arrays, --std_dev_values, and --mean_values. The flags must have the same number of items. The current input arrays are '{0}'. --input_arrays must be present when specifying --std_dev_values and --mean_values with multiple input tensors in order to map between names and values.": "Mismatching --input_arrays, --std_dev_values, and --mean_values. The flags must have the same number of items. The current input arrays are '{0}'. --input_arrays must be present when specifying --std_dev_values and --mean_values with multiple input tensors in order to map between names and values.",
  "Invalid value for --target_ops. Options: {0}": "Invalid value for --target_ops. Options: {0}",
  "--experimental_select_user_tf_ops can only be set if --target_ops contains SELECT_TF_OPS.": "--experimental_select_user_tf_ops can only be set if --target_ops contains SELECT_TF_OPS.",
  "--input_arrays and --output_arrays are required with --graph_def_file": "--input_arrays and --output_arrays are required with --graph_def_file",
  "--input_shapes must be used with --input_arrays": "--input_shapes must be used with --input_arrays",
  "--input_shapes and --input_arrays must have the same number of items": "--input_shapes and --input_arrays must have the same number of items",
  "--std_dev_values and --mean_values must be used together": "--std_dev_values and --mean_values must be used together",
  "--std_dev_values, --mean_values must have the same number of items": "--std_dev_values, --mean_values must have the same number of items",
  "--default_ranges_min and --default_ranges_max must be used together": "--default_ranges_min and --default_ranges_max must be used together",
  "--dump_graphviz_video must be used with --dump_graphviz_dir": "--dump_graphviz_video must be used with --dump_graphviz_dir",
  "--custom_opdefs must be used with --experimental_new_converter": "--custom_opdefs must be used with --experimental_new_converter",
  "--custom_opdefs must be used with --allow_custom_ops": "--custom_opdefs must be used with --allow_custom_ops",
  "--experimental_select_user_tf_ops must be used with --experimental_new_converter": "--experimental_select_user_tf_ops must be used with --experimental_new_converter",
  "one of the arguments --saved_model_dir --keras_model_file is required": "one of the arguments --saved_model_dir --keras_model_file is required",
  "Model {} cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling `.fit()` or `.predict()`. To manually set the shapes, call `model.build(input_shape)`.": "Model {} cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling `.fit()` or `.predict()`. To manually set the shapes, call `model.build(input_shape)`.",
  "Unsupported enum {}. The valid map of enum to tf types is : {}": "Unsupported enum {}. The valid map of enum to tf types is : {}",
  "Tensor name invalid. Expect 0 or 1 colon, got {0}": "Tensor name invalid. Expect 0 or 1 colon, got {0}",
  "Invalid type for a tensor name in the provided graph. Expected type for a tensor name is 'str', instead got type '{}' for tensor name '{}'": "Invalid type for a tensor name in the provided graph. Expected type for a tensor name is 'str', instead got type '{}' for tensor name '{}'",
  "Invalid tensors '{}' were found.": "Invalid tensors '{}' were found.",
  "Invalid tensor '{}' found in tensor shapes map.": "Invalid tensor '{}' found in tensor shapes map.",
  "Try to convert op hints, needs unfrozen graph.": "Try to convert op hints, needs unfrozen graph.",
  "Model must only have one subgraph. Instead, it has {} subgraphs.": "Model must only have one subgraph. Instead, it has {} subgraphs.",
  "Model input is not dequantized.": "Model input is not dequantized.",
  "Initial model input type must be tf.float32. Expected type for tensor with name '{}' is tf.float32, instead type is {}": "Initial model input type must be tf.float32. Expected type for tensor with name '{}' is tf.float32, instead type is {}",
  "Initial model input is not quantized. Expected type for tensor with name '{}' should be in {}, instead type is {}": "Initial model input is not quantized. Expected type for tensor with name '{}' should be in {}, instead type is {}",
  "Unsupported `inference_input_type` value. Expected to be in {}, instead got {}.": "Unsupported `inference_input_type` value. Expected to be in {}, instead got {}.",
  "Unsupported `inference_input_type` value {}.": "Unsupported `inference_input_type` value {}.",
  "Model output is not dequantized.": "Model output is not dequantized.",
  "Initial model output type must be tf.float32. Expected type for tensor with name '{}' is tf.float32, instead type is {}": "Initial model output type must be tf.float32. Expected type for tensor with name '{}' is tf.float32, instead type is {}",
  "Initial model output is not dequantized. Expected type for tensor with name '{}' should be in {}, instead type is {}": "Initial model output is not dequantized. Expected type for tensor with name '{}' should be in {}, instead type is {}",
  "Unsupported `inference_output_type` value. Expected to be in {}, instead got {}.": "Unsupported `inference_output_type` value. Expected to be in {}, instead got {}.",
  "Unsupported `inference_output_type` value {}.": "Unsupported `inference_output_type` value {}.",
  "`model_content` must be specified.": "`model_content` must be specified.",
  "Failed to parse the model: %s.": "Failed to parse the model: %s.",
  "Failed to parse the model.": "Failed to parse the model.",
  "Could not populate marker text %r": "Could not populate marker text %r",
  "Failed to generate HTML: file '{0}' doesn't exist.": "Failed to generate HTML: file '{0}' doesn't exist.",
  "Invalid filename %r": "Invalid filename %r",
  "Input file was not .tflite or .json": "Input file was not .tflite or .json",
  "can only convert string messages for now.": "can only convert string messages for now.",
  "Unexpected keyword argument values, %s, for function %s": "Unexpected keyword argument values, %s, for function %s",
  "\"%s\" requires a positional first argument as the target": "\"%s\" requires a positional first argument as the target",
  "\"%s\" must be the first statement in the loop block": "\"%s\" must be the first statement in the loop block",
  "\"%s\" must be used inside a statement": "\"%s\" must be used inside a statement",
  "multiple assignments": "multiple assignments",
  "%s has ambiguous annotations for %s(%s): %s, %s": "%s has ambiguous annotations for %s(%s): %s, %s",
  "converter objects cannot be reused": "converter objects cannot be reused",
  "mangled names are not yet supported": "mangled names are not yet supported",
  "for/else statement not yet supported": "for/else statement not yet supported",
  "while/else statement not yet supported": "while/else statement not yet supported",
  "generators are not supported": "generators are not supported",
  "Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead.": "Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead.",
  "either caller_fn_scope or options must have a value": "either caller_fn_scope or options must have a value",
  "unknown callable type \"%s\"": "unknown callable type \"%s\"",
  "element_dtype and element_shape are required when elements are empty": "element_dtype and element_shape are required when elements are empty",
  "unknown type for elements: {}; only Tensor, list and tuple are allowed": "unknown type for elements: {}; only Tensor, list and tuple are allowed",
  "%s must be stackable when strict=True": "%s must be stackable when strict=True",
  "condition of {} expected to be `tf.bool` scalar, got {}; to use as boolean Tensor, use `tf.cast`; {}": "condition of {} expected to be `tf.bool` scalar, got {}; to use as boolean Tensor, use `tf.cast`; {}",
  "condition of {} expected to be `tf.bool` scalar, got {}; {}": "condition of {} expected to be `tf.bool` scalar, got {}; {}",
  "the return value from a TensorFlow loop may only be a {}; got {}": "the return value from a TensorFlow loop may only be a {}; got {}",
  "a return statement cannot be placed inside this TensorFlow loop; this may happen if a return statement depends on a static Python condition such as a hyperparameter": "a return statement cannot be placed inside this TensorFlow loop; this may happen if a return statement depends on a static Python condition such as a hyperparameter",
  "'{}' is None at the end of the iteration.": "'{}' is None at the end of the iteration.",
  "'{}' has dtype {} before the loop, but dtype {} after one iteration": "'{}' has dtype {} before the loop, but dtype {} after one iteration",
  "'{}' has shape {} before the loop, but shape {} after one iteration. Use tf.autograph.experimental.set_loop_options to set shape invariants.": "'{}' has shape {} before the loop, but shape {} after one iteration. Use tf.autograph.experimental.set_loop_options to set shape invariants.",
  "'{}' has shape {} before the loop, which does not conform with\" the shape invariant {}.": "'{}' has shape {} before the loop, which does not conform with\" the shape invariant {}.",
  "'{}' has shape {} after one iteration, which does not conform with the shape invariant {}.": "'{}' has shape {} after one iteration, which does not conform with the shape invariant {}.",
  "'{}' does not have the same nested structure after one iteration.\n\n{}": "'{}' does not have the same nested structure after one iteration.\n\n{}",
  "'{}' does not have the same nested structure as its corresponding shape invariant.\n\n{}": "'{}' does not have the same nested structure as its corresponding shape invariant.\n\n{}",
  "'{}' is None at the end of the main branch.": "'{}' is None at the end of the main branch.",
  "'{}' is None at the end of the else branch.": "'{}' is None at the end of the else branch.",
  "'{}' has dtype {} in the main branch, but dtype {} in the else branch": "'{}' has dtype {} in the main branch, but dtype {} in the else branch",
  "'{}' must also be initialized in the {} branch": "'{}' must also be initialized in the {} branch",
  "the {} branch must also have a return statement.": "the {} branch must also have a return statement.",
  "'{}' must have the same nested structure in the main and else branches:\n\n{}": "'{}' must have the same nested structure in the main and else branches:\n\n{}",
  "break and return statements are not yet supported in for ... in distributed input loops.": "break and return statements are not yet supported in for ... in distributed input loops.",
  "iteration limit exceeded": "iteration limit exceeded",
  "incompatible dtype; specified: {}, inferred from {}: {}": "incompatible dtype; specified: {}, inferred from {}: {}",
  "TensorArray requires all elements to have the same dtype: {}": "TensorArray requires all elements to have the same dtype: {}",
  "dtype is required to create an empty TensorArray": "dtype is required to create an empty TensorArray",
  "incompatible shape; specified: {}, inferred from {}: {}": "incompatible shape; specified: {}, inferred from {}: {}",
  "TensorArray requires all elements to have the same shape: {}": "TensorArray requires all elements to have the same shape: {}",
  "element shape may not be specified when creating list from tensor": "element shape may not be specified when creating list from tensor",
  "specified dtype {} is inconsistent with that of elements {}": "specified dtype {} is inconsistent with that of elements {}",
  "specified shape {} is inconsistent with that of elements {}": "specified shape {} is inconsistent with that of elements {}",
  "tensor lists are expected to be Tensors with dtype=tf.variant, instead found %s": "tensor lists are expected to be Tensors with dtype=tf.variant, instead found %s",
  "TensorArray does not support item removal": "TensorArray does not support item removal",
  "tensor lists only support removing from the end": "tensor lists only support removing from the end",
  "cannot pop from a list without knowing its element type; use set_element_type to annotate it": "cannot pop from a list without knowing its element type; use set_element_type to annotate it",
  "cannot pop from a list without knowing its element shape; use set_element_type to annotate it": "cannot pop from a list without knowing its element type; use set_element_type to annotate it",
  "cannot stack a list without knowing its element type; use set_element_type to annotate it": "cannot stack a list without knowing its element type; use set_element_type to annotate it",
  "{} must be a callable": "{} must be a callable",
  "{} may not have any arguments": "{} may not have any arguments",
  "base {} not supported for int": "base {} not supported for int",
  "len requires a non-scalar tensor, got one of shape {}": "len requires a non-scalar tensor, got one of shape {}",
  "invalid keyword arguments: {}": "invalid keyword arguments: {}",
  "use a for loop over the dataset and keep a separate counter": "use a for loop over the dataset and keep a separate counter",
  "{} cannot be None": "{} cannot be None",
  "{} must have the same dtype as {}. Expected {}, got {}": "{} must have the same dtype as {}. Expected {}, got {}",
  "{} must have the same element structure as {}.\\n\\n{}": "{} must have the same element structure as {}.\n\n{}",
  "in graph mode, the \"any\" builtin only supports datasets that return bool scalars; got: {}": "in graph mode, the \"any\" builtin only supports datasets that return bool scalars; got: {}",
  "in graph mode, the \"all\" builtin only supports datasets that return bool scalars; got: {}": "in graph mode, the \"any\" builtin only supports datasets that return bool scalars; got: {}",
  "sort only supports only 1D tensors": "sort only supports only 1D tensors",
  "cannot retrieve from a list without knowing its element type; use set_element_type to annotate it": "cannot retrieve from a list without knowing its element type; use set_element_type to annotate it",
  "'{}' is used before assignment": "'{}' is used before assignment",
  "inconsistent nodes: {} ({}) and {} ({})": "inconsistent nodes: {} ({}) and {} ({})",
  "inconsistent values for field {}: {} and {}": "inconsistent values for field {}: {} and {}",
  "subclasses must override": "subclasses must override",
  "Subclasses must implement this.": "Subclasses must implement this.",
  "%s added twice": "%s added twice",
  "%s that is not enclosed by any of %s": "%s that is not enclosed by any of %s",
  "Found too many owners of %s: %s": "Found too many owners of %s: %s",
  "Unexpected symbol type \"%s\"": "Unexpected symbol type \"%s\"",
  "code mixing tabs and spaces for indentation is not allowed": "code mixing tabs and spaces for indentation is not allowed",
  "Unable to locate the source code of {}. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: {}": "Unable to locate the source code of {}. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: {}",
  "could not parse the source code of {}: no matching AST found": "could not parse the source code of {}: no matching AST found",
  "could not parse the source code of {}: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n{}": "could not parse the source code of {}: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n{}",
  "expected exactly one node, found {}": "expected exactly one node, found {}",
  "expected a single expression, found instead {}": "expected a single expression, found instead {}",
  "A QN can only be either an attr or a subscript, not both: attr={}, subscript={}.": "A QN can only be either an attr or a subscript, not both: attr={}, subscript={}.",
  "for attribute QNs, base must be a QN; got instead \"%s\"": "for attribute QNs, base must be a QN; got instead \"%s\"",
  "attr may only be a string; got instead \"%s\"": "attr may only be a string; got instead \"%s\"",
  "For subscript QNs, base must be a QN.": "For subscript QNs, base must be a QN.",
  "for simple QNs, base must be a string or a Literal object; got instead \"%s\"": "for simple QNs, base must be a string or a Literal object; got instead \"%s\"",
  "Cannot get attr of non-attribute \"%s\".": "Cannot get attr of non-attribute \"%s\".",
  "Cannot get parent of simple name \"%s\".": "Cannot get parent of simple name \"%s\".",
  "a keyword argument may only be replaced by another keyword or a non-empty list of keywords. Found: {} for keyword {}": "a keyword argument may only be replaced by another keyword or a non-empty list of keywords. Found: {} for keyword {}",
  "a function name can only be replaced by a Name node. Found: %s": "a function name can only be replaced by a Name node. Found: %s",
  "An attribute can only be replaced by a Name node. Found: %s": "An attribute can only be replaced by a Name node. Found: %s",
  "Expected string template, got %s": "Expected string template, got %s",
  "single expression expected; for more general templates use replace": "single expression expected; for more general templates use replace",
  "the template is expected to generate an expression or a name node; instead found %s": "the template is expected to generate an expression or a name node; instead found %s",
  "double initialization; create a new object instead": "double initialization; create a new object instead",
  "call create first": "call create first",
  "closure mismatch, requested {}, but source function had {}": "closure mismatch, requested {}, but source function had {}",
  "Unknown node type {}": "Unknown node type {}",
  "subclasses must override this": "subclasses must override this",
  "Non-function: {}": "Non-function: {}",
  "Unknown context {} for node \"{}\".": "Unknown context {} for node \"{}\".",
  "subclasses must implement": "subclasses must implement",
  "{} method expected to return set, got {}": "{} method expected to return set, got {}",
  "side effect keys must be QNs, got {}": "side effect keys must be QNs, got {}",
  "at least one argument required": "at least one argument required",
  "if use_dummy_return is True, return_dtypes must be empty": "if use_dummy_return is True, return_dtypes must be empty",
  "argument %d was used with MatchDType and must be a tf.Tensor, but was %s instead": "argument %d was used with MatchDType and must be a tf.Tensor, but was %s instead",
  "%s has already been registered so ignore it.": "%s has already been registered so ignore it.",
  "Fetch argument %r has invalid type %r": "Fetch argument %r has invalid type %r",
  "Fetch argument %r cannot be interpreted as a Tensor. (%s)": "Fetch argument %r cannot be interpreted as a Tensor. (%s)",
  "graph must be a tf.Graph, but got %s": "graph must be a tf.Graph, but got %s",
  "target must be a string, but got %s. Did you do \"Session(config)\" instead of' \"Session(config=config)\"?": "target must be a string, but got %s. Did you do \"Session(config)\" instead of' \"Session(config=config)\"?",
  "config must be a tf.ConfigProto, but got %s": "config must be a tf.ConfigProto, but got %s",
  "Feed argument %r has invalid type %r": "Feed argument %r has invalid type %r",
  "Attempted to use a closed Session.": "Attempted to use a closed Session.",
  "The Session graph is empty.  Add operations to the graph before calling run().": "The Session graph is empty.  Add operations to the graph before calling run().",
  "Cannot interpret feed_dict key as Tensor: {}": "Cannot interpret feed_dict key as Tensor: {}",
  "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles. For reference, the tensor object was {} which was passed to the feed with key {}.": "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles. For reference, the tensor object was {} which was passed to the feed with key {}.",
  "Type of feed value {} with type {} is not compatible with Tensor type {}. Try explicitly setting the type of the feed tensor to a larger type (e.g. int64).": "Type of feed value {} with type {} is not compatible with Tensor type {}. Try explicitly setting the type of the feed tensor to a larger type (e.g. int64).",
  "Cannot feed value of shape %r for Tensor %r, which has shape %r": "Cannot feed value of shape %r for Tensor %r, which has shape %r",
  "Tensor %s may not be fed.": "Tensor %s may not be fed.",
  "`feed_list` must be a list or tuple.": "`feed_list` must be a list or tuple.",
  "partial_run() requires empty target_list.": "partial_run() requires empty target_list.",
  "Session context managers are not re-entrant. Use `Session.as_default()` if you want to enter a session multiple times.": "Session context managers are not re-entrant. Use `Session.as_default()` if you want to enter a session multiple times.",
  "Windows platform is not supported": "Windows platform is not supported",
  "precision mode '{}' is not supported. It should be one of {}": "precision mode '{}' is not supported. It should be one of {}",
  "Incompatible TensorRT versions": "Incompatible TensorRT versions",
  "Incompatible TensorRT major version": "Incompatible TensorRT major version",
  "is_dynamic_op is either None or True for TF2": "is_dynamic_op is either None or True for TF2",
  "is_dynamic_op can't be None for TF1": "is_dynamic_op can't be None for TF1",
  "max_batch_size has to be None for TF2 or when is_dynamic_op == True in TF1": "max_batch_size has to be None for TF2 or when is_dynamic_op == True in TF1",
  "max_batch_size has to be an integer for is_dynamic_op==False in TF1": "max_batch_size has to be an integer for is_dynamic_op==False in TF1",
  "Please use tf.experimental.tensorrt.Converter in TF 2.0.": "Please use tf.experimental.tensorrt.Converter in TF 2.0.",
  "Can only specify one of input_graph_def and input_saved_model_dir": "Can only specify one of input_graph_def and input_saved_model_dir",
  "Must specify one of input_graph_def and input_saved_model_dir": "Must specify one of input_graph_def and input_saved_model_dir",
  "When is_dynamic_op==False max_batch_size should be an integer": "When is_dynamic_op==False max_batch_size should be an integer",
  "Should specify one and only one of feed_dict_fn and input_map_fn.": "Should specify one and only one of feed_dict_fn and input_map_fn.",
  "Keys of input_map_fn must be of type str": "Keys of input_map_fn must be of type str",
  "Values of input_map_fn must be of type tf.Tensor": "Values of input_map_fn must be of type tf.Tensor",
  "Not able to save to a SavedModel since input is a GraphDef": "Not able to save to a SavedModel since input is a GraphDef",
  "profile_strategy '{}' is not supported. It should be one of {}": "profile_strategy '{}' is not supported. It should be one of {}",
  "Should specify calibration_input_fn because INT8 calibration is needed": "Should specify calibration_input_fn because INT8 calibration is needed",
  "Should specify calibration_input_fn because INT8 calibration is not needed": "Should specify calibration_input_fn because INT8 calibration is not needed",
  "build() is already called. It is not supported to call build() more than once.": "build() is already called. It is not supported to call build() more than once.",
  "input_fn is None. Method build() needs input_fn to be specified in order to build TensorRT engines": "input_fn is None. Method build() needs input_fn to be specified in order to build TensorRT engines",
  "build() is not called . Explicit batch mode (use_implicit_batch=False) requires generating TensorRT optimization profiles which is done by calling build().": "build() is not called . Explicit batch mode (use_implicit_batch=False) requires generating TensorRT optimization profiles which is done by calling build().",
  "'_Canonicalize' can only be used on strings or sequence of strings!": "'_Canonicalize' can only be used on strings or sequence of strings!",
  "'_RemoveGraphSequenceNumberImpl' can only be used on strings or sequence of strings!": "'_RemoveGraphSequenceNumberImpl' can only be used on strings or sequence of strings!",
  "xla.experimental.jit_scope is not supported when eager execution is enabled. Try use it inside tf.function.": "xla.experimental.jit_scope is not supported when eager execution is enabled. Try use it inside tf.function.",
  "Non-resource Variables are not supported inside XLA computations (operator name: %s)": "Non-resource Variables are not supported inside XLA computations (operator name: %s)",
  "XLA compiled computations cannot be nested, (operator name: %s)": "XLA compiled computations cannot be nested, (operator name: %s)",
  "inputs must be a list": "inputs must be a list",
  "XLA computation function return values must all either be Operations or convertible to Tensors. Got error: \"%s\"": "XLA computation function return values must all either be Operations or convertible to Tensors. Got error: \"%s\"",
  "XLA computation function must return zero or more Tensor values followed by zero or more Operations.": "XLA computation function must return zero or more Tensor values followed by zero or more Operations.",
  "xla.compile does not support Operation as return value in non-flat output structure. You can set returned Operations as control dependencies of returned Tensors so Operations are triggered when Tensors are evaluated. Operation found: \"%s\"": "xla.compile does not support Operation as return value in non-flat output structure. You can set returned Operations as control dependencies of returned Tensors so Operations are triggered when Tensors are evaluated. Operation found: \"%s\"",
  "InternalError: _CapturedObject can capture only once. Please file bug.": "InternalError: _CapturedObject can capture only once. Please file bug.",
  "TPUEstimatorSpec.scaffold_fn returns None, which is not allowed": "TPUEstimatorSpec.scaffold_fn returns None, which is not allowed",
  "Eager mode benchmarking is not supported in graph mode.": "Eager mode benchmarking is not supported in graph mode.",
  "Graph mode benchmarking is not supported in eager mode.": "Graph mode benchmarking is not supported in eager mode.",
  "Trying to restart the dispatcher without fault-tolerance.": "Trying to restart the dispatcher without fault-tolerance.",
  "The `num_parallel_batches` and `num_parallel_calls` arguments are mutually exclusive.": "The `num_parallel_batches` and `num_parallel_calls` arguments are mutually exclusive.",
  "DenseToSparseDataset requires an input whose elements have a single component, whereas the input has %r.": "DenseToSparseDataset requires an input whose elements have a single component, whereas the input has %r.",
  "{0} is not a valid processing mode. Valid modes: {1}": "{0} is not a valid processing mode. Valid modes: {1}",
  "job_name must be set when setting num_consumers": "job_name must be set when setting num_consumers",
  "service must be a string, but service was of type {0}. service={1}": "service must be a string, but service was of type {0}. service={1}",
  "service must not be empty": "service must not be empty",
  "malformed service string has multiple '://': %s": "malformed service string has multiple '://': %s",
  "Invalid compression argument: {}. Must be one of {}": "Invalid compression argument: {}. Must be one of {}",
  "job_name must be a string, but job_name was of type {0}. job_name={1}": "job_name must be a string, but job_name was of type {0}. job_name={1}",
  "job_name must not be empty": "job_name must not be empty",
  "element_spec must not be None": "element_spec must not be None",
  "Expected batch_sizes to be a scalar or vector.": "Expected batch_sizes to be a scalar or vector.",
  "Expected a dataset whose elements have rank >= 1 but found a dataset whose elements are scalars. You can fix the issue by adding the `batch` transformation to the dataset.": "Expected a dataset whose elements have rank >= 1 but found a dataset whose elements are scalars. You can fix the issue by adding the `batch` transformation to the dataset.",
  "Batch dimensions of input dataset are not compatible.": "Batch dimensions of input dataset are not compatible.",
  "`dataset` must be a `tf.data.Dataset` object.": "`dataset` must be a `tf.data.Dataset` object.",
  "%s._to_proto() is called with undefined enum %s.": "%s._to_proto() is called with undefined enum %s.",
  "`key_func` must return a single tf.int64 tensor. Got type=%s and shape=%s": "`key_func` must return a single tf.int64 tensor. Got type=%s and shape=%s",
  "The element classes for the new state must match the initial state. Expected %s; got %s.": "The element classes for the new state must match the initial state. Expected %s; got %s.",
  "The element types for the new state must match the initial state. Expected %s; got %s.": "The element types for the new state must match the initial state. Expected %s; got %s.",
  "All datasets must have the same type and class.\ndataset 0 vs dataset %s types: %s ; %s\nclasses: %s ; %s": "All datasets must have the same type and class.\ndataset 0 vs dataset %s types: %s ; %s\nclasses: %s ; %s",
  "`datasets` must be a non-empty list of datasets.": "`datasets` must be a non-empty list of datasets.",
  "`weights` must have the same length as `datasets`.": "`weights` must have the same length as `datasets`.",
  "`weights` must be convertible to a tensor of `tf.float32` or `tf.float64` elements.": "`weights` must be convertible to a tensor of `tf.float32` or `tf.float64` elements.",
  "`choice_dataset` must be a dataset of scalar `tf.int64` tensors.": "`choice_dataset` must be a dataset of scalar `tf.int64` tensors.",
  "Failed to convert {} to an instance of ExternalStatePolicy. Supported values include: 'warn', 'ignore' and 'fail'": "Failed to convert {} to an instance of ExternalStatePolicy. Supported values include: 'warn', 'ignore' and 'fail'",
  "element spec size should be 2": "element spec size should be 2",
  "elem_spec[0] should be of type TensorSpec, got: %s": "elem_spec[0] should be of type TensorSpec, got: %s",
  "elem_spec[1] should be of type TensorSpec, got: %s": "elem_spec[1] should be of type TensorSpec, got: %s",
  "key tensor should be a scalar": "key tensor should be a scalar",
  "value tensor should be a scalar": "value tensor should be a scalar",
  "The given dataset must contain pairs.": "The given dataset must contain pairs.",
  "The dtype of the values requires manually setting a compatible default_value.": "The dtype of the values requires manually setting a compatible default_value.",
  "num_oov_buckets must be greater or equal than 0, got %d.": "num_oov_buckets must be greater or equal than 0, got %d.",
  "vocab_size must be greater than 0, got %d.": "vocab_size must be greater than 0, got %d.",
  "Only integer and string keys are supported.": "Only integer and string keys are supported.",
  "`elems` must be a list of tensors.": "`elems` must be a list of tensors.",
  "`output_dtypes` must be a list of `tf.DType` objects.": "`output_dtypes` must be a list of `tf.DType` objects.",
  "`output_shapes` must be a list of `tf.TensorShape` objects.": "`output_shapes` must be a list of `tf.TensorShape` objects.",
  "Input dataset should be a dataset of vectors of strings": "Input dataset should be a dataset of vectors of strings",
  "Missing: features was %s.": "Missing: features was %s.",
  "Cannot create a one shot iterator when using `tf.data.experimental.copy_to_device()` on GPU. Please use `Dataset.make_initializable_iterator()` instead.": "Cannot create a one shot iterator when using `tf.data.experimental.copy_to_device()` on GPU. Please use `Dataset.make_initializable_iterator()` instead.",
  "Problem inferring types: CSV row has different number of fields than expected.": "Problem inferring types: CSV row has different number of fields than expected.",
  "Received StopIteration when reading the header line of %s.  Empty file?": "Received StopIteration when reading the header line of %s.  Empty file?",
  "Files have different column names in the header row.": "Files have different column names in the header row.",
  "Column index %d specified in select_columns out of valid range.": "Column index %d specified in select_columns out of valid range.",
  "Value '%s' specified in select_columns not a valid column index or name.": "Value '%s' specified in select_columns not a valid column index or name.",
  "select_columns contains duplicate columns": "select_columns contains duplicate columns",
  "Received unknown compression_type": "Received unknown compression_type",
  "compression_type (%s) is not supported for probing columns": "compression_type (%s) is not supported for probing columns",
  "compression_type (%s) is not supported": "compression_type (%s) is not supported",
  "Cannot infer column names without a header line.": "Cannot infer column names without a header line.",
  "Cannot have duplicate column names.": "Cannot have duplicate column names.",
  "If specified, column_defaults and select_columns must have same length.": "If specified, column_defaults and select_columns must have same length.",
  "`label_name` provided must be one of the columns.": "`label_name` provided must be one of the columns.",
  "The `reader` argument must return a `Dataset` object. `tf.ReaderBase` subclasses are not supported. For example, pass `tf.data.TFRecordDataset` instead of `tf.TFRecordReader`.": "The `reader` argument must return a `Dataset` object. `tf.ReaderBase` subclasses are not supported. For example, pass `tf.data.TFRecordDataset` instead of `tf.TFRecordReader`.",
  "The `label_key` provided (%r) must be one of the `features` keys.": "The `label_key` provided (%r) must be one of the `features` keys.",
  "File pattern is empty.": "File pattern is empty.",
  "No files match %s.": "No files match %s.",
  "At least one transformation should be specified": "At least one transformation should be specified",
  "`dataset` must produce scalar `DT_STRING` tensors whereas it produces shape {0} and types {1}": "`dataset` must produce scalar `DT_STRING` tensors whereas it produces shape {0} and types {1}",
  "Cannot enable fault tolerant mode without configuring a work_dir": "Cannot enable fault tolerant mode without configuring a work_dir",
  "must specify a dispatcher_address": "must specify a dispatcher_address",
  "Dataset ended early, producing %d elements out of %d. Dataset output: %s": "Dataset ended early, producing %d elements out of %d. Dataset output: %s",
  "Expected dataset to raise an error of type %s, but it did not.": "Expected dataset to raise an error of type %s, but it did not.",
  "Unrecognized init_source: ": "Unrecognized init_source: ",
  "The input_dataset._dataset of dataset %s should be DatasetV2.": "The input_dataset._dataset of dataset %s should be DatasetV2.",
  "Unexpected dataset type: ": "Unexpected dataset type: ",
  "The _variant_tensor property is read-only": "The _variant_tensor property is read-only",
  "Can only export Datasets which were created executing eagerly. Please file a feature request if this is important to you.": "Can only export Datasets which were created executing eagerly. Please file a feature request if this is important to you.",
  "Found multiple return values from the dataset's graph, expected only one.": "Found multiple return values from the dataset's graph, expected only one.",
  "Could not find the dataset's output node.": "Could not find the dataset's output node.",
  "The _graph property is read-only": "The _graph property is read-only",
  "__iter__() is only supported inside of tf.function or when eager execution is enabled.": "__iter__() is only supported inside of tf.function or when eager execution is enabled.",
  "__len__() is not supported while tracing functions. Use `tf.data.Dataset.cardinality` instead.": "__len__() is not supported while tracing functions. Use `tf.data.Dataset.cardinality` instead.",
  "dataset length is infinite.": "dataset length is infinite.",
  "dataset length is unknown.": "dataset length is unknown.",
  "as_numpy_iterator() is not supported while tracing functions": "as_numpy_iterator() is not supported while tracing functions",
  "Dataset.as_numpy_iterator() does not support datasets containing {}": "Dataset.as_numpy_iterator() does not support datasets containing {}",
  "`generator` must be callable.": "`generator` must be callable.",
  "`output_types` can not be used together with `output_signature`": "`output_types` can not be used together with `output_signature`",
  "`output_shapes` can not be used together with `output_signature`": "`output_shapes` can not be used together with `output_signature`",
  "All the elements of `output_signature` must be `tf.TypeSpec` objects.": "All the elements of `output_signature` must be `tf.TypeSpec` objects.",
  "Either `output_signature` or `output_types` must be specified": "Either `output_signature` or `output_types` must be specified",
  "`generator` yielded an element of type %s where an element of type %s was expected.": "`generator` yielded an element of type %s where an element of type %s was expected.",
  "`generator` yielded an element of shape %s where an element of shape %s was expected.": "`generator` yielded an element of shape %s where an element of shape %s was expected.",
  "`generator` yielded an element of %s where an element of %s was expected.": "`generator` yielded an element of %s where an element of %s was expected.",
  "You must set the `padded_shapes` argument to `Dataset.padded_batch` if any component of its input has an unknown rank": "You must set the `padded_shapes` argument to `Dataset.padded_batch` if any component of its input has an unknown rank",
  "`transformation_func` must return a Dataset. Got {}.": "`transformation_func` must return a Dataset. Got {}.",
  "Must pass either window_size or window_size_func.": "Must pass either window_size or window_size_func.",
  "len(bucket_batch_sizes) must equal len(bucket_boundaries) + 1": "len(bucket_batch_sizes) must equal len(bucket_boundaries) + 1",
  "Please use _variant_tensor instead of _as_variant_tensor() to obtain the variant associated with a dataset": "Please use _variant_tensor instead of _as_variant_tensor() to obtain the variant associated with a dataset",
  "{}: A likely cause of this error is that the super call for this dataset is not the last line of the __init__ method. The base class causes the _as_variant_tensor call in its constructor and if that uses attributes defined in the __init__ method, those attrs need to be defined before the super call.": "{}: A likely cause of this error is that the super call for this dataset is not the last line of the __init__ method. The base class causes the _as_variant_tensor call in its constructor and if that uses attributes defined in the __init__ method, those attrs need to be defined before the super call.",
  "Dataset._as_variant_tensor": "Dataset._as_variant_tensor",
  "Failed to create a one-shot iterator for a dataset. `Dataset.make_one_shot_iterator()` does not support datasets that capture stateful objects, such as a `Variable` or `LookupTable`. In these cases, use `Dataset.make_initializable_iterator()`. (Original error: %s)": "Failed to create a one-shot iterator for a dataset. `Dataset.make_one_shot_iterator()` does not support datasets that capture stateful objects, such as a `Variable` or `LookupTable`. In these cases, use `Dataset.make_initializable_iterator()`. (Original error: %s)",
  "dataset.make_initializable_iterator is not supported when eager execution is enabled. Use `for element in dataset` instead.": "dataset.make_initializable_iterator is not supported when eager execution is enabled. Use `for element in dataset` instead.",
  "The graph {} of the iterator is different from the graph {} the dataset: {} was  created in. If you are using the Estimator API, make sure that no part of the dataset returned by the `input_fn` function is defined outside the `input_fn` function. Please ensure that all datasets in the pipeline are created in the same graph as the iterator.": "The graph {} of the iterator is different from the graph {} the dataset: {} was  created in. If you are using the Estimator API, make sure that no part of the dataset returned by the `input_fn` function is defined outside the `input_fn` function. Please ensure that all datasets in the pipeline are created in the same graph as the iterator.",
  "`dataset_or_iterator` must be a `tf.data.Dataset` or tf.data.Iterator object, but got %s.": "`dataset_or_iterator` must be a `tf.data.Dataset` or tf.data.Iterator object, but got %s.",
  "Attribute %s not found.": "Attribute %s not found.",
  "`sparse_tensor` must be a `tf.sparse.SparseTensor` object.Was {}.": "`sparse_tensor` must be a `tf.sparse.SparseTensor` object.Was {}.",
  "Unbatching a dataset is only supported for rank >= 1": "Unbatching a dataset is only supported for rank >= 1",
  "Either `dataset`, `input_structure` or all of `input_classes`, `input_shapes`, and `input_types` must be specified.": "Either `dataset`, `input_structure` or all of `input_classes`, `input_shapes`, and `input_types` must be specified.",
  "Two datasets to concatenate have different types %s and %s": "Two datasets to concatenate have different types %s and %s",
  "Two datasets to concatenate have different classes %s and %s": "Two datasets to concatenate have different classes %s and %s",
  "Invalid arguments to RangeDataset: %s": "Invalid arguments to RangeDataset: %s",
  "The padded shape %s is not compatible with the corresponding input component shape %s.": "The padded shape %s is not compatible with the corresponding input component shape %s.",
  "Padding value should be a scalar, but is not: %s": "Padding value should be a scalar, but is not: %s",
  "Padding value tensor (%s) does not match output type: %s": "Padding value tensor (%s) does not match output type: %s",
  "Padded batching of components of type {} is not supported.": "Padded batching of components of type {} is not supported.",
  "`map_func` must return a `Dataset` object. Got {}": "`map_func` must return a `Dataset` object. Got {}",
  "Cannot unbatch an input with scalar components.": "Cannot unbatch an input with scalar components.",
  "Cannot unbatch an input whose components have different batch sizes.": "Cannot unbatch an input whose components have different batch sizes.",
  "`window_size_func` must return a single tf.int64 scalar tensor.": "`window_size_func` must return a single tf.int64 scalar tensor.",
  "`key_func` must return a single tf.int64 scalar tensor.": "`key_func` must return a single tf.int64 scalar tensor.",
  "`reduce_func` must return a `Dataset` object.": "`reduce_func` must return a `Dataset` object.",
  "`predicate` must return a scalar boolean tensor.": "`predicate` must return a scalar boolean tensor.",
  "`tf.data.Dataset.unique()` only supports inputs with a single `tf.int32`, `tf.int64`, or `tf.string` component.": "`tf.data.Dataset.unique()` only supports inputs with a single `tf.int32`, `tf.int64`, or `tf.string` component.",
  "shard_func must return a 0-dimension tensor containing an int.": "shard_func must return a 0-dimension tensor containing an int.",
  "The scan function must return a pair comprising the new state and the output value.": "The scan function must return a pair comprising the new state and the output value.",
  "Debug mode is only supported in eager mode.": "Debug mode is only supported in eager mode.",
  "If `structure` is not specified, all of `output_types`, `output_shapes`, and `output_classes` must be specified.": "If `structure` is not specified, all of `output_types`, `output_shapes`, and `output_classes` must be specified.",
  "Iterator does not have an initializer.": "Iterator does not have an initializer.",
  "Expected output classes %r but got dataset with output class %r.": "Expected output classes %r but got dataset with output class %r.",
  "Expected output types %r but got dataset with output types %r.": "Expected output types %r but got dataset with output types %r.",
  "Expected output shapes compatible with %r but got dataset with output shapes %r.": "Expected output shapes compatible with %r but got dataset with output shapes %r.",
  "Eager reset is only supported in eager mode.": "Eager reset is only supported in eager mode.",
  "OwnedMultiDeviceIterator is only supported inside of tf.function or when eager execution is enabled.": "OwnedMultiDeviceIterator is only supported inside of tf.function or when eager execution is enabled.",
  "`devices` must be provided": "`devices` must be provided",
  "Either `dataset` or both `components` and `element_spec` need to be provided.": "Either `dataset` or both `components` and `element_spec` need to be provided.",
  "`filenames` must be a `tf.data.Dataset` of `tf.string` elements.": "`filenames` must be a `tf.data.Dataset` of `tf.string` elements.",
  "`filenames` must be a `tf.data.Dataset` of scalar `tf.string` elements.": "`filenames` must be a `tf.data.Dataset` of scalar `tf.string` elements.",
  "`filenames` must be a `tf.Tensor` of dtype `tf.string` dtype. Got {}": "`filenames` must be a `tf.Tensor` of dtype `tf.string` dtype. Got {}",
  "`map_func` must return a `Dataset` object.": "`map_func` must return a `Dataset` object.",
  "The given shape %s must be a 1-D tensor of tf.int64 values, but the shape was %s.": "The given shape %s must be a 1-D tensor of tf.int64 values, but the shape was %s.",
  "nest only supports dicts with sortable keys.": "nest only supports dicts with sortable keys.",
  "flat_sequence must be a sequence": "flat_sequence must be a sequence",
  "Structure is a scalar but len(flat_sequence) == %d > 1": "Structure is a scalar but len(flat_sequence) == %d > 1",
  "Could not pack sequence. Structure had %d elements, but flat_sequence had %d elements.  Structure: %s, flat_sequence: %s.": "Could not pack sequence. Structure had %d elements, but flat_sequence had %d elements.  Structure: %s, flat_sequence: %s.",
  "func must be callable, got: %s": "func must be callable, got: %s",
  "Must provide at least one structure": "Must provide at least one structure",
  "Only valid keyword argument is check_types": "Only valid keyword argument is check_types",
  "If shallow structure is a sequence, input must also be a sequence. Input has type: %s.": "If shallow structure is a sequence, input must also be a sequence. Input has type: %s.",
  "The two structures don't have the same sequence type. Input structure has type %s, while shallow structure has type %s.": "The two structures don't have the same sequence type. Input structure has type %s, while shallow structure has type %s.",
  "The two structures don't have the same sequence length. Input structure has length %s, while shallow structure has length %s.": "The two structures don't have the same sequence length. Input structure has length %s, while shallow structure has length %s.",
  "The two structures don't have the same keys. Input structure has keys %s, while shallow structure has keys %s.": "The two structures don't have the same keys. Input structure has keys %s, while shallow structure has keys %s.",
  "Cannot map over no sequences": "Cannot map over no sequences",
  "Mutating `tf.data.Options()` returned by `tf.data.Dataset.options()` has no effect. Use `tf.data.Dataset.with_options(options)` to set or update dataset options.": "Mutating `tf.data.Options()` returned by `tf.data.Dataset.options()` has no effect. Use `tf.data.Dataset.with_options(options)` to set or update dataset options.",
  "Cannot set the property %s on %s.": "Cannot set the property %s on %s.",
  "Property \"%s\" must be of type %s, got: %r (type: %r)": "Property \"%s\" must be of type %s, got: %r (type: %r)",
  "At least one options should be provided": "At least one options should be provided",
  "Incompatible options type: %r vs %r": "Incompatible options type: %r vs %r",
  "The inputs should inherit from `OptionsBase`": "The inputs should inherit from `OptionsBase`",
  "Could not build a structure for output class %r": "Could not build a structure for output class %r",
  "Expected %d tensors but got %d.": "Expected %d tensors but got %d.",
  "Could not build a TypeSpec for %r with type %s": "Could not build a TypeSpec for %r with type %s",
  "No TypeSpec is compatible with both %s and %s": "No TypeSpec is compatible with both %s and %s",
  "Input argument filter_name is expected to be str, but is not.": "Input argument filter_name is expected to be str, but is not.",
  "Input argument filter_name cannot be empty.": "Input argument filter_name cannot be empty.",
  "Input argument filter_callable is expected to be callable, but is not.": "Input argument filter_callable is expected to be callable, but is not.",
  "There is no tensor filter named \"%s\"": "There is no tensor filter named \"%s\"",
  "The flag --filter_exclude_node_names is valid only when the flag -f or --tensor_filter is used.": "The flag --filter_exclude_node_names is valid only when the flag -f or --tensor_filter is used.",
  "run_ui() is not implemented in BaseUI": "run_ui() is not implemented in BaseUI",
  "%s is not a valid property name.": "%s is not a valid property name.",
  "Invalid string value for bool type: %s": "Invalid string value for bool type: %s",
  "Unsupported property type: %s": "Unsupported property type: %s",
  "The callback object provided is not callable.": "The callback object provided is not callable.",
  "Invalid time unit: %s": "Invalid time unit: %s",
  "Redirect file path is empty": "Redirect file path is empty",
  "Invalid tensor-slicing string.": "Invalid tensor-slicing string.",
  "Incorrect number of elements in range": "Incorrect number of elements in range",
  "Incorrect type in the 1st element of range: %s": "Incorrect type in the 1st element of range: %s",
  "Incorrect type in the 2nd element of range: %s": "Incorrect type in the 2nd element of range: %s",
  "Invalid interval %s. Start of interval must be less than or equal to end of interval.": "Invalid interval %s. Start of interval must be less than or equal to end of interval.",
  "Invalid interval %s. Start must be before end of interval.": "Invalid interval %s. Start must be before end of interval.",
  "Invalid value string after <= in '%s'": "Invalid value string after <= in '%s'",
  "Invalid value string after < in '%s'": "Invalid value string after < in '%s'",
  "Invalid value string after >= in '%s'": "Invalid value string after >= in '%s'",
  "Invalid value string after > in '%s'": "Invalid value string after > in '%s'",
  "Invalid interval format: %s. Valid formats are: [min, max], (min, max), <max, >min": "Invalid interval format: %s. Valid formats are: [min, max], (min, max), <max, >min",
  "Incorrect interval format: %s. Interval should specify two values: [min, max] or (min, max).": "Incorrect interval format: %s. Interval should specify two values: [min, max] or (min, max).",
  "Invalid first item in interval: '%s'": "Invalid first item in interval: '%s'",
  "Invalid second item in interval: '%s'": "Invalid second item in interval: '%s'",
  "Failed to parsed human-readable byte size str: \"%s\"": "Failed to parsed human-readable byte size str: \"%s\"",
  "Invalid time %s. Time value must be positive.": "Invalid time %s. Time value must be positive.",
  "Insufficient width for ScrollBar (%d)": "Insufficient width for ScrollBar (%d)",
  "Key validator expected type int, received type %s": "Key validator expected type int, received type %s",
  "Invalid type in row": "Invalid type in row",
  "Output is required to be an instance of RichTextLines, but is not.": "Output is required to be an instance of RichTextLines, but is not.",
  "Input color_segments needs to be a list, but is not.": "Input color_segments needs to be a list, but is not.",
  "Invalid line_index type (%s) under mode %s": "Invalid line_index type (%s) under mode %s",
  "Unsupported scroll mode: %s": "Unsupported scroll mode: %s",
  "In valid capacity value: %d": "In valid capacity value: %d",
  "Empty navigation history": "Empty navigation history",
  "%r cannot be concatenated with a RichLine": "%r cannot be concatenated with a RichLine",
  "Unexpected type in lines: %s": "Unexpected type in lines: %s",
  "Encountered negative index.": "Encountered negative index.",
  "Invalid regular expression: \"%s\"": "Invalid regular expression: \"%s\"",
  "Invalid type of input screen_output": "Invalid type of input screen_output",
  "Invalid type of input cols": "Invalid type of input cols",
  "Empty command prefix": "Empty command prefix",
  "A handler is already registered for command prefix \"%s\"": "A handler is already registered for command prefix \"%s\"",
  "handler is not callable": "handler is not callable",
  "help_info is not a str": "help_info is not a str",
  "The prefix alias \"%s\" clashes with existing prefixes or aliases.": "The prefix alias \"%s\" clashes with existing prefixes or aliases.",
  "Prefix is empty": "Prefix is empty",
  "No handler is registered for command prefix \"%s\"": "No handler is registered for command prefix \"%s\"",
  "Return value from command handler %s is not None or a RichTextLines instance": "Return value from command handler %s is not None or a RichTextLines instance",
  "Incorrect type in context_list: Expected list, got %s": "Incorrect type in context_list: Expected list, got %s",
  "Cannot deregister unregistered context word \"%s\"": "Cannot deregister unregistered context word \"%s\"",
  "Context word \"%s\" has not been registered": "Context word \"%s\" has not been registered",
  "Attempt to enter non-str entry to command history": "Attempt to enter non-str entry to command history",
  "There is no menu item with the caption \"%s\"": "There is no menu item with the caption \"%s\"",
  "The debug tensor name in the to-be-evaluated expression is malformed: '%s'": "The debug tensor name in the to-be-evaluated expression is malformed: '%s'",
  "Eval failed due to the value of %s:%d:DebugIdentity being unavailable": "Eval failed due to the value of %s:%d:DebugIdentity being unavailable",
  "Invalid column index %d.": "Invalid column index %d.",
  "No RunMetadata passed for profile analysis.": "No RunMetadata passed for profile analysis.",
  "Unsupported cost type: %s": "Unsupported cost type: %s",
  "tensor_metadata is not available in annotations.": "tensor_metadata is not available in annotations.",
  "Dimensions mismatch: requested: %d; actual: %d": "Dimensions mismatch: requested: %d; actual: %d",
  "Indices exceed tensor dimensions.": "Indices exceed tensor dimensions.",
  "Indices contain negative value(s).": "Indices contain negative value(s).",
  "Input indices sets are not in ascending order.": "Input indices sets are not in ascending order.",
  "Invalid ui_type: '%s'": "Invalid ui_type: '%s'",
  "Exhausted all fallback ui_types.": "Exhausted all fallback ui_types.",
  "Dump file path does not conform to the naming pattern: %s": "Dump file path does not conform to the naming pattern: %s",
  "Dump root directory %s does not exist": "Dump root directory %s does not exist",
  "No partition graphs loaded for device %s": "No partition graphs loaded for device %s",
  "Node name '%s' is not found in partition graphs of device %s.": "Node name '%s' is not found in partition graphs of device %s.",
  "Causality violated in timing relations of debug dumps: %s (%d): these input(s) are not satisfied: %s": "Causality violated in timing relations of debug dumps: %s (%d): these input(s) are not satisfied: %s",
  "No partition graphs have been loaded.": "No partition graphs have been loaded.",
  "There are multiple (%d) devices with nodes named '%s' but device_name is not specified.": "There are multiple (%d) devices with nodes named '%s' but device_name is not specified.",
  "None of the %d device(s) has a node named '%s'.": "None of the %d device(s) has a node named '%s'.",
  "Invalid device name: %s": "Invalid device name: %s",
  "Node inputs are not loaded from partition graphs yet.": "Node inputs are not loaded from partition graphs yet.",
  "Source (%s) and destination (%s) are not on the same device: %s vs. %s": "Source (%s) and destination (%s) are not on the same device: %s vs. %s",
  "Node recipients are not loaded from partition graphs yet.": "Node recipients are not loaded from partition graphs yet.",
  "Nodes have not been loaded from partition graphs yet.": "Nodes have not been loaded from partition graphs yet.",
  "The specified device_name '%s' cannot be found.": "The specified device_name '%s' cannot be found.",
  "Node devices are not loaded from partition graphs yet.": "Node devices are not loaded from partition graphs yet.",
  "Node '%s' does not exist in partition graphs.": "Node '%s' does not exist in partition graphs.",
  "Node op types are not loaded from partition graphs yet.": "Node op types are not loaded from partition graphs yet.",
  "The debug watch key '%s' exists on multiple (%d) devices, but device name is not specified.": "The debug watch key '%s' exists on multiple (%d) devices, but device name is not specified.",
  "There is no device named '%s' consisting of debug watch keys.": "There is no device named '%s' consisting of debug watch keys.",
  "Watch key \"%s\" does not exist in the debug dump of device %s": "Watch key \"%s\" does not exist in the debug dump of device %s",
  "Watch key \"%s\" does not exist in the debug dump": "Watch key \"%s\" does not exist in the debug dump",
  "Python graph is not available for traceback lookup": "Python graph is not available for traceback lookup",
  "Cannot find node \"%s\" in Python graph": "Cannot find node \"%s\" in Python graph",
  "Specified dump_root is not a directory: %s": "Specified dump_root is not a directory: %s",
  "Cannot find any tfdbg metadata file in directory: %s": "Cannot find any tfdbg metadata file in directory: %s",
  "Found %d tfdbg metadata files and %d of them do not have tfdbg run ids. The metadata files without run ids are: %s": "Found %d tfdbg metadata files and %d of them do not have tfdbg run ids. The metadata files without run ids are: %s",
  "Unexpected: Found multiple (%d) tfdbg2 runs in directory %s": "Unexpected: Found multiple (%d) tfdbg2 runs in directory %s",
  "Duplicate op name: %s (op type: %s)": "Duplicate op name: %s (op type: %s)",
  "Empty or None dump root": "Empty or None dump root",
  "The graph already contains an op named %s": "The graph already contains an op named %s",
  "The graph of the value (%s) is not the same as the graph %s": "The graph of the value (%s) is not the same as the graph %s",
  "This GradientsDebugger has not received any gradient tensor for x-tensor %s": "This GradientsDebugger has not received any gradient tensor for x-tensor %s",
  "x_tensor must be a str or tf.Tensor or tf.Variable, but instead has type %s": "x_tensor must be a str or tf.Tensor or tf.Variable, but instead has type %s",
  "This GradientsDebugger instance has a graph (%s) that differs from the graph of the DebugDumpDir object (%s).": "This GradientsDebugger instance has a graph (%s) that differs from the graph of the DebugDumpDir object (%s).",
  "Invalid prefix in debug node name: '%s'": "Invalid prefix in debug node name: '%s'",
  "Invalid debug node name: '%s'": "Invalid debug node name: '%s'",
  "Invalid tensor name in debug node name: '%s'": "Invalid tensor name in debug node name: '%s'",
  "Duplicate node name on device %s: '%s'": "Duplicate node name on device %s: '%s'",
  "debug_ops must not be empty or None.": "debug_ops must not be empty or None.",
  "debug_urls must not be empty or None.": "debug_urls must not be empty or None.",
  "Symbolic tensor instrumentation is not implemented for debug mode %s": "Symbolic tensor instrumentation is not implemented for debug mode %s",
  "Tensor instrumentation is not implemented for debug mode %s yet ": "Tensor instrumentation is not implemented for debug mode %s yet ",
  "Invalid value in tensor_debug_mode ('%s'). Valid options are: %s": "Invalid value in tensor_debug_mode ('%s'). Valid options are: %s",
  "tfdbg dumping: support for tensor debug mode %s is not implemented yet": "tfdbg dumping: support for tensor debug mode %s is not implemented yet",
  "If specified, tensor_dtypes is expected to be a list, a tuple, or a callable that takes a DType argument and returns a boolean, but received %s": "If specified, tensor_dtypes is expected to be a list, a tuple, or a callable that takes a DType argument and returns a boolean, but received %s",
  "There is already a dumping callback configured with a different circular-buffer size (%d). Therefore the newly request circular-buffer size (%d) will not be honored.": "There is already a dumping callback configured with a different circular-buffer size (%d). Therefore the newly request circular-buffer size (%d) will not be honored.",
  "There is already a dumping callback configured for dump root %s with a different tensor-debug mode (%s). Therefore the newly request tensor-debug mode (%s) size will not be honored.": "There is already a dumping callback configured for dump root %s with a different tensor-debug mode (%s). Therefore the newly request tensor-debug mode (%s) size will not be honored.",
  "on_core_metadata_event() is not implemented in the base servicer class": "on_core_metadata_event() is not implemented in the base servicer class",
  "on_graph_def() is not implemented in the base servicer class": "on_graph_def() is not implemented in the base servicer class",
  "on_value_event() is not implemented in the base servicer class": "on_value_event() is not implemented in the base servicer class",
  "Expected one core metadata event; received multiple": "Expected one core metadata event; received multiple",
  "Server has already stopped": "Server has already stopped",
  "Server has already started running": "Server has already started running",
  "Server has not started running": "Server has not started running",
  "The value lacks plugin data.": "The value lacks plugin data.",
  "Could not parse content into JSON: %r, %r": "Could not parse content into JSON: %r, %r",
  "Op '%s' does not exist in the tracebacks received by the debug server.": "Op '%s' does not exist in the tracebacks received by the debug server.",
  "This debug server has not received any source file contents yet.": "This debug server has not received any source file contents yet.",
  "Source file at path %s has not been received by the debug server": "Source file at path %s has not been received by the debug server",
  "Failed to start test gRPC debug server at port %d": "Failed to start test gRPC debug server at port %d",
  "Empty cluster_spec string": "Empty cluster_spec string",
  "Not exactly one instance of '|' in cluster_spec": "Not exactly one instance of '|' in cluster_spec",
  "Empty job_name in cluster_spec": "Empty job_name in cluster_spec",
  "Empty task string at position %d": "Empty task string at position %d",
  "Empty job_name": "Empty job_name",
  "Invalid task_id: %d": "Invalid task_id: %d",
  "_debug_urls() method is not implemented in the base test class.": "_debug_urls() method is not implemented in the base test class.",
  "_debug_dump_dir() method is not implemented in the base test class.": "_debug_dump_dir() method is not implemented in the base test class.",
  "_get_concurrent_debug_urls is not implemented in the base test class": "_get_concurrent_debug_urls is not implemented in the base test class",
  "Source path neither exists nor can be loaded as a .par file: %s": "Source path neither exists nor can be loaded as a .par file: %s",
  "Cannot perform source annotation due to a lack of set Python graph in the dump object": "Cannot perform source annotation due to a lack of set Python graph in the dump object",
  "Cannot generate source list due to a lack of set Python graph in the dump object": "Cannot generate source list due to a lack of set Python graph in the dump object",
  "session_root path points to a file: %s": "session_root path points to a file: %s",
  "session_root path points to a non-empty directory: %s": "session_root path points to a non-empty directory: %s",
  "Expected type %s; got type %s": "Expected type %s; got type %s",
  "OnSessionInitAction REMOTE_INSTR_LOOP has not been implemented.": "OnSessionInitAction REMOTE_INSTR_LOOP has not been implemented.",
  "Invalid OnSessionInitAction value: %s": "Invalid OnSessionInitAction value: %s",
  "callable_runner and callable_options are mutually exclusive, but are both specified in this call to BaseDebugWrapperSession.run().": "callable_runner and callable_options are mutually exclusive, but are both specified in this call to BaseDebugWrapperSession.run().",
  "callable_runner and fetches/feed_dict are mutually exclusive, but are used simultaneously.": "callable_runner and fetches/feed_dict are mutually exclusive, but are used simultaneously.",
  "callable_options and fetches/feed_dict are mutually exclusive, but are used simultaneously.": "callable_options and fetches/feed_dict are mutually exclusive, but are used simultaneously.",
  "Invalid OnRunStartAction value: %s": "Invalid OnRunStartAction value: %s",
  "partial_run_setup is not implemented for debug-wrapper sessions.": "partial_run_setup is not implemented for debug-wrapper sessions.",
  "partial_run is not implemented for debug-wrapper sessions.": "partial_run is not implemented for debug-wrapper sessions.",
  "The wrapped session %r does not have a method called 'should_stop'. Do you intend to wrap a tf.MonitoredSession instead?": "The wrapped session %r does not have a method called 'should_stop'. Do you intend to wrap a tf.MonitoredSession instead?",
  "watch_fn is not callable": "watch_fn is not callable",
  "Expected type str in list grpc_debug_server_addresses, received type %s": "Expected type str in list grpc_debug_server_addresses, received type %s",
  "Expected type str or list in grpc_debug_server_addresses, received type %s": "Expected type str or list in grpc_debug_server_addresses, received type %s",
  "dump_root path points to a file: %s": "dump_root path points to a file: %s",
  "dump_root path points to a non-empty directory: %s": "dump_root path points to a non-empty directory: %s",
  "The --filter_exclude_node_names (or -feon) flag is valid only if the --till_filter_pass (or -f) flag is used.": "The --filter_exclude_node_names (or -feon) flag is valid only if the --till_filter_pass (or -f) flag is used.",
  "InputReplicationMode.PER_REPLICA is only supported in `experimental_distribute_datasets_from_function`.": "InputReplicationMode.PER_REPLICA is only supported in `experimental_distribute_datasets_from_function`.",
  "communication_options must be an instance of tf.distribute.experimental.CommunicationOptions": "communication_options must be an instance of tf.distribute.experimental.CommunicationOptions",
  "cluster_resolver must be an instance of tf.distribute.cluster_resolver.ClusterResolver": "cluster_resolver must be an instance of tf.distribute.cluster_resolver.ClusterResolver",
  "When `cluster_spec` is given, you must also specify `task_type` and `task_id`.": "When `cluster_spec` is given, you must also specify `task_type` and `task_id`.",
  "No `worker`, `chief` or `evaluator` tasks can be found in `cluster_spec`.": "No `worker`, `chief` or `evaluator` tasks can be found in `cluster_spec`.",
  "InputReplicationMode.PER_REPLICA is only supported in  `experimental_distribute_datasets_from_function` of tf.distribute.MirroredStrategy": "InputReplicationMode.PER_REPLICA is only supported in  `experimental_distribute_datasets_from_function` of tf.distribute.MirroredStrategy",
  "Timeout waiting for the cluster, timeout is %d seconds": "Timeout waiting for the cluster, timeout is %d seconds",
  "MultiWorkerMirroredStrategy cannot be deep copied in eager mode. If you're using Estimator and see this error message, call tf.compat.v1.disable_eager_execution() at the beginning of your program": "MultiWorkerMirroredStrategy cannot be deep copied in eager mode. If you're using Estimator and see this error message, call tf.compat.v1.disable_eager_execution() at the beginning of your program",
  "bytes_per_pack must be non-negative": "bytes_per_pack must be non-negative",
  "implementation should be a tf.distribute.experimental.CommunicationImplementation": "implementation should be a tf.distribute.experimental.CommunicationImplementation",
  "Only support one NamedDistribution for multi workertests.": "Only support one NamedDistribution for multi workertests.",
  "both has_chief and strategy specified but are not compatible": "both has_chief and strategy specified but are not compatible",
  "both num_workers and strategy specified but are not compatible": "both num_workers and strategy specified but are not compatible",
  "Do not use `required_gpus` and arguments of type NamedDistribution together.": "Do not use `required_gpus` and arguments of type NamedDistribution together.",
  "Only one of `required_physical_gpus`(number of physical GPUs required) and `required_gpus`(total number of GPUs required) should be set. ": "Only one of `required_physical_gpus`(number of physical GPUs required) and `required_gpus`(total number of GPUs required) should be set. ",
  "Do not use `required_tpu`.  Both `required_tpus` and `required_tpu` were specified.": "Do not use `required_tpu`.  Both `required_tpus` and `required_tpu` were specified.",
  "Do not use `required_tpus` and arguments of type NamedDistribution together.": "Do not use `required_tpus` and arguments of type NamedDistribution together.",
  "combinations.env() should only be modified in the main process. Condition your code on combinations.in_main_process().": "combinations.env() should only be modified in the main process. Condition your code on combinations.in_main_process().",
  "destinations must be one of a `DistributedValues` object, a tf.Variable object, or a device string.": "destinations must be one of a `DistributedValues` object, a tf.Variable object, or a device string.",
  "destinations can not be empty": "destinations can not be empty",
  "You are passing a `DistributedValues` to `reduce_non_distributed_value`, which is not allowed.": "You are passing a `DistributedValues` to `reduce_non_distributed_value`, which is not allowed.",
  "A non-DistributedValues value %s cannot be reduced with the given reduce op %s.": "A non-DistributedValues value %s cannot be reduced with the given reduce op %s.",
  "Cannot convert `input_tensor` to a `PerReplica` object, got %r but expected a object that is not a tuple or list.": "Cannot convert `input_tensor` to a `PerReplica` object, got %r but expected a object that is not a tuple or list.",
  "Cannot convert `input_tensor` to a `PerReplica` object because it doesn't have device set.": "Cannot convert `input_tensor` to a `PerReplica` object because it doesn't have device set.",
  "`value_destination_pairs` should be a list or tuple": "`value_destination_pairs` should be a list or tuple",
  "Each element of `value_destination_pairs` should be a tuple.": "Each element of `value_destination_pairs` should be a tuple.",
  "Each element of `value_destination_pairs` should be a tuple of size 2.": "Each element of `value_destination_pairs` should be a tuple of size 2.",
  "`per_replica_value` must be non-empty": "`per_replica_value` must be non-empty",
  "`reduce_op` must be Reduce.SUM or Reduce.MEAN.": "`reduce_op` must be Reduce.SUM or Reduce.MEAN.",
  "gather/all_gather does not support IndexedSlices": "gather/all_gather does not support IndexedSlices",
  "_gather method must be implemented in descendants.": "_gather method must be implemented in descendants.",
  "_reduce method must be implemented in descendants.": "_reduce method must be implemented in descendants.",
  "batch_reduce_implementation method must be implemented in descendants.": "batch_reduce_implementation method must be implemented in descendants.",
  "_all_reduce must be implemented in descendants.": "_all_reduce must be implemented in descendants.",
  "num_packs must be greater than zero.": "num_packs must be greater than zero.",
  "NCCL all-reduce requires num_packs >= 0, but {} is specified": "NCCL all-reduce requires num_packs >= 0, but {} is specified",
  "HierarchicalCopy requires num_packs >= 0, but {} is specified": "HierarchicalCopy requires num_packs >= 0, but {} is specified",
  "group_size must be divisible by the number of devices.": "group_size must be divisible by the number of devices.",
  "cluster_spec must be a `tf.train.ClusterSpec`.": "cluster_spec must be a `tf.train.ClusterSpec`.",
  "master must be a string.": "master must be a string.",
  "Unexpected kwargs provided {!r}": "Unexpected kwargs provided {!r}",
  "At least one ClusterResolver is required.": "At least one ClusterResolver is required.",
  "All arguments must be a sub-class of `ClusterResolver.`": "All arguments must be a sub-class of `ClusterResolver.`",
  "Duplicate keys detected when merging two ClusterSpecs: %s": "Duplicate keys detected when merging two ClusterSpecs: %s",
  "googleapiclient must be installed before using the GCE cluster resolver": "googleapiclient must be installed before using the GCE cluster resolver",
  "You cannot reset the task_type of the GCEClusterResolver after it has been created.": "You cannot reset the task_type of the GCEClusterResolver after it has been created.",
  "The Kubernetes Python client must be installed before using the Kubernetes Cluster Resolver. To install the Kubernetes Python client, run `pip install kubernetes` on your command line.": "The Kubernetes Python client must be installed before using the Kubernetes Cluster Resolver. To install the Kubernetes Python client, run `pip install kubernetes` on your command line.",
  "Pod \"%s\" is not running; phase: \"%s\"": "Pod \"%s\" is not running; phase: \"%s\"",
  "Invalid part: %s": "Invalid part: %s",
  "Invalid hostlist format \"%s\": %s": "Invalid hostlist format \"%s\": %s",
  "Invalid tasks-per-node list format \"%s\": %s": "Invalid tasks-per-node list format \"%s\": %s",
  "%s not found in environment. Not running inside a SLURM step?": "%s not found in environment. Not running inside a SLURM step?",
  "Could not get number of GPUs from nvidia-smi. Maybe it is missing?\nOutput: %s": "Could not get number of GPUs from nvidia-smi. Maybe it is missing?\nOutput: %s",
  "Requested more GPUs per node then available.": "Requested more GPUs per node then available.",
  "Requested {} tasks but only {} were assigned.": "Requested {} tasks but only {} were assigned.",
  "TPU cores on each device is not the same. This should never happen. Devices: {}": "TPU cores on each device is not the same. This should never happen. Devices: {}",
  "No TPUs with the specified names exist.": "No TPUs with the specified names exist.",
  "Failed to connect to master. The TPU might not be ready (e.g. still scheduling) or the master address is incorrect: got (%s)": "Failed to connect to master. The TPU might not be ready (e.g. still scheduling) or the master address is incorrect: got (%s)",
  "RemoteValue doesn't have a value because it has errors.": "RemoteValue doesn't have a value because it has errors.",
  "Output of a scheduled function that is not tf.function cannot be the input of another function.": "Output of a scheduled function that is not tf.function cannot be the input of another function.",
  "`tf.distribute.experimental.coordinator.RemoteValue` used as an input to scheduled function is not yet supported.": "`tf.distribute.experimental.coordinator.RemoteValue` used as an input to scheduled function is not yet supported.",
  "Function passed to `ClusterCoordinator.schedule` must be a callable object.": "Function passed to `ClusterCoordinator.schedule` must be a callable object.",
  "There is no inflight closures to mark_finished.": "There is no inflight closures to mark_finished.",
  "There is no inflight closures to put_back.": "There is no inflight closures to put_back.",
  "There is no inflight closures to mark_failed.": "There is no inflight closures to mark_failed.",
  "_set_dead is not implemented.": "_set_dead is not implemented.",
  "Resource being registered is not of type `tf.distribute.experimental.coordinator.RemoteValue`.": "Resource being registered is not of type `tf.distribute.experimental.coordinator.RemoteValue`.",
  "Only `tf.distribute.experimental.ParameterServerStrategy` is supported to work with `tf.distribute.experimental.coordinator.ClusterCoordinator` currently.": "Only `tf.distribute.experimental.ParameterServerStrategy` is supported to work with `tf.distribute.experimental.coordinator.ClusterCoordinator` currently.",
  "`tf.distribute.experimental.coordinator.ClusterCoordinator.schedule` only accepts a `tf.function` or a concrete function.": "`tf.distribute.experimental.coordinator.ClusterCoordinator.schedule` only accepts a `tf.function` or a concrete function.",
  "Unexpected task_type to start a server: {}": "Unexpected task_type to start a server: {}",
  "Must be implemented in subclasses.": "Must be implemented in subclasses.",
  "The corresponding function is aborted. Please reschedule the function.": "The corresponding function is aborted. Please reschedule the function.",
  "`PerWorkerValues` should only take `RemoteValue`s.": "`PerWorkerValues` should only take `RemoteValue`s.",
  "most_specific_compatible_type is not implemented": "most_specific_compatible_type is not implemented",
  "Creating variables in `dataset_fn` is not allowed.": "Creating variables in `dataset_fn` is not allowed.",
  "__iter__() is not supported inside of tf.function or in graph mode.": "__iter__() is not supported inside of tf.function or in graph mode.",
  "`element_spec` is not supported when the `dataset_fn` is not a `ConcreteFunction`.": "`element_spec` is not supported when the `dataset_fn` is not a `ConcreteFunction`.",
  "Iterating over an `AsyncDistributedIterator` is not supported right now.": "Iterating over an `AsyncDistributedIterator` is not supported right now.",
  "{} is not a parallel device": "{} is not a parallel device",
  "ParallelDevice requires at least one component.": "ParallelDevice requires at least one component.",
  "Creating a parallel tensor requires one tensor per component. Got {} but was expecting {}.": "Creating a parallel tensor requires one tensor per component. Got {} but was expecting {}.",
  "Every component must already be a tensor, got {}. Consider running `tf.constant` or `tf.convert_to_tensor` first on literal values.": "Every component must already be a tensor, got {}. Consider running `tf.constant` or `tf.convert_to_tensor` first on literal values.",
  "Expected a tensor, got {}.": "Expected a tensor, got {}.",
  "ParallelDevice is currently not supported inside `tf.function`. It can however run calls to a `tf.function` in parallel:\n\nwith ParallelDevice() as p:\n  f()": "ParallelDevice is currently not supported inside `tf.function`. It can however run calls to a `tf.function` in parallel:\n\nwith ParallelDevice() as p:\n  f()",
  "Re-entered a ParallelDevice scope without first exiting it.": "Re-entered a ParallelDevice scope without first exiting it.",
  "tensors cannot be empty": "tensors cannot be empty",
  "Tensors must have statically known shape.": "Tensors must have statically known shape.",
  "input tensor must be 1D": "input tensor must be 1D",
  "tensors must be 1D": "tensors must be 1D",
  "pad_len longer than tensor": "pad_len longer than tensor",
  "num_subchunks %d must be <= num_gpus %d": "num_subchunks %d must be <= num_gpus %d",
  "input_tensors must be length 2 or longer": "input_tensors must be length 2 or longer",
  "input tensors must be 1D": "input tensors must be 1D",
  "Expect number of chunks per device to be divisible by num_devices": "Expect number of chunks per device to be divisible by num_devices",
  "num_devices must be a power of 2": "num_devices must be a power of 2",
  "input_tensors must be 1D": "input_tensors must be 1D",
  "len(devices) must equal len(values)": "len(devices) must equal len(values)",
  "red_op not supported by NCCL all-reduce: {}": "red_op not supported by NCCL all-reduce: {}",
  "For shuffle hybrid, gather_devices must contain one device per worker. {}": "For shuffle hybrid, gather_devices must contain one device per worker. {}",
  "tf.GradientTape.gradients() does not support graph control flow operations like tf.cond or tf.while at this time. Use tf.gradients() instead. If you need this feature, please file a feature request at https://github.com/tensorflow/tensorflow/issues/new": "tf.GradientTape.gradients() does not support graph control flow operations like tf.cond or tf.while at this time. Use tf.gradients() instead. If you need this feature, please file a feature request at https://github.com/tensorflow/tensorflow/issues/new",
  "Cannot differentiate a function that returns None; did you forget to return a value from {}?": "Cannot differentiate a function that returns None; did you forget to return a value from {}?",
  "No trainable variables were accessed while the function was being computed.": "No trainable variables were accessed while the function was being computed.",
  "GradientTape.gradient is not supported on packed EagerTensors yet.": "GradientTape.gradient is not supported on packed EagerTensors yet.",
  "Either callable provided is not a function or could not inspect its arguments by name: %s. Original error: %s": "Either callable provided is not a function or could not inspect its arguments by name: %s. Original error: %s",
  "params must be all strings or all integers; got %s.": "params must be all strings or all integers; got %s.",
  "Functions to be differentiated cannot receive keyword arguments.": "Functions to be differentiated cannot receive keyword arguments.",
  "`grad` not a Tensor or IndexedSlices.": "`grad` not a Tensor or IndexedSlices.",
  "Tape is still recording, This can happen if you try to re-enter an already-active tape.": "Tape is still recording, This can happen if you try to re-enter an already-active tape.",
  "Tape is not recording.": "Tape is not recording.",
  "Passed in object of type {}, not tf.Tensor": "Passed in object of type {}, not tf.Tensor",
  "Trying to stop recording a tape which is not recording.": "Trying to stop recording a tape which is not recording.",
  "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)": "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)",
  "Target should be a list or nested structure of Tensors or Variables to be differentiated, but recieved %r": "Target should be a list or nested structure of Tensors or Variables to be differentiated, but recieved %r",
  "GradientTape must be created with persistent=True to compute the jacobian with eager execution enabled and with  experimental_use_pfor set to False.": "GradientTape must be created with persistent=True to compute the jacobian with eager execution enabled and with  experimental_use_pfor set to False.",
  "Need first dimension of target shape (%s) and source shape (%s) to match.": "Need first dimension of target shape (%s) and source shape (%s) to match.",
  "GradientTape must be created with persistent=True to compute the batch_jacobian with parallel_iterations.": "GradientTape must be created with persistent=True to compute the batch_jacobian with parallel_iterations.",
  "GradientTape must be created with persistent=True to compute the batch_jacobian.": "GradientTape must be created with persistent=True to compute the batch_jacobian.",
  "GradientTape must be created with persistent=True to compute the batch_jacobian with eager execution enabled and  with experimental_use_pfor set to False.": "GradientTape must be created with persistent=True to compute the batch_jacobian with eager execution enabled and  with experimental_use_pfor set to False.",
  "the rewriter config must be either a config_pb2.ConfigProto, or a serialized string of that proto or None. got: {}": "the rewriter config must be either a config_pb2.ConfigProto, or a serialized string of that proto or None. got: {}",
  "execution_mode should be None/SYNC/ASYNC. Got %s": "execution_mode should be None/SYNC/ASYNC. Got %s",
  "server_def is None.": "server_def is None.",
  "Context is not initialized.": "Context is not initialized.",
  "Collective ops are already configured.": "Collective ops are already configured.",
  "Collective ops must be configured at program startup": "Collective ops must be configured at program startup",
  "Context must be initialized first.": "Context must be initialized first.",
  "Execution mode should be None/SYNC/ASYNC. Got %s": "Execution mode should be None/SYNC/ASYNC. Got %s",
  "priority must be specified for all virtual devices": "priority must be specified for all virtual devices",
  "Memory growth cannot differ between GPU devices": "Memory growth cannot differ between GPU devices",
  "The specified op callback has not been registered, and hence cannot be removed.": "The specified op callback has not been registered, and hence cannot be removed.",
  "device must be a tf.config.PhysicalDevice, but got: %s": "device must be a tf.config.PhysicalDevice, but got: %s",
  "The PhysicalDevice must be one obtained from calling `tf.config.list_physical_devices`, but got: %s": "The PhysicalDevice must be one obtained from calling `tf.config.list_physical_devices`, but got: %s",
  "Device returned compute capability an in invalid format: %s": "Device returned compute capability an in invalid format: %s",
  "Invalid visible device index: %s": "Invalid visible device index: %s",
  "Unrecognized device: %s": "Unrecognized device: %s",
  "Visible devices cannot be modified after being initialized": "Visible devices cannot be modified after being initialized",
  "Cannot set memory growth on device when virtual devices configured": "Cannot set memory growth on device when virtual devices configured",
  "Cannot set memory growth on non-GPU devices": "Cannot set memory growth on non-GPU devices",
  "Physical devices cannot be modified after being initialized": "Physical devices cannot be modified after being initialized",
  "Setting memory limit on CPU virtual devices is currently not supported": "Setting memory limit on CPU virtual devices is currently not supported",
  "Setting experimental_priority on CPU virtual  devices is currently not supported": "Setting experimental_priority on CPU virtual  devices is currently not supported",
  "Setting memory limit is required for GPU virtual devices": "Setting memory limit is required for GPU virtual devices",
  "Virtual devices are not supported for %s": "Virtual devices are not supported for %s",
  "Virtual devices cannot be modified after being initialized": "Virtual devices cannot be modified after being initialized",
  "Virtual CPUs already set, cannot modify again.": "Virtual CPUs already set, cannot modify again.",
  "Intra op parallelism cannot be modified after initialization.": "Intra op parallelism cannot be modified after initialization.",
  "Inter op parallelism cannot be modified after initialization.": "Inter op parallelism cannot be modified after initialization.",
  "Expecting a boolean but got %s": "Expecting a boolean but got %s",
  "use_tfrt should be set before being initialized.": "use_tfrt should be set before being initialized.",
  "Expecting a string device name. Got %s(%s)": "Expecting a string device name. Got %s(%s)",
  "Exiting device scope without proper scope nesting": "Exiting device scope without proper scope nesting",
  "initial_value must be specified.": "initial_value must be specified.",
  "The `constraint` argument must be a callable.": "The `constraint` argument must be a callable.",
  "Some but not all components of a parallel variable {} were initialized between their creation in a tf.function and the function's trace having completed. This is not yet supported; consider initializing either all or none of the components, or moving initialization out of the function.": "Some but not all components of a parallel variable {} were initialized between their creation in a tf.function and the function's trace having completed. This is not yet supported; consider initializing either all or none of the components, or moving initialization out of the function.",
  "tf.function-decorated function tried to create variables on non-first call.": "tf.function-decorated function tried to create variables on non-first call.",
  "Functions cannot be decorated after they have been traced.": "Functions cannot be decorated after they have been traced.",
  "Creating variables on a non-first call to a function decorated with tf.function.": "Creating variables on a non-first call to a function decorated with tf.function.",
  "Compiler IR can only be returned for functions marked with 'jit_compile=True'": "Compiler IR can only be returned for functions marked with 'jit_compile=True'",
  "get_initialization_function cannot be called after the function has been used": "get_initialization_function cannot be called after the function has been used",
  "Inputs to eager execution function cannot be Keras symbolic tensors, but found {}": "Inputs to eager execution function cannot be Keras symbolic tensors, but found {}",
  "Expected float for argument '%s' not %s.": "Expected float for argument '%s' not %s.",
  "Expected int for argument '%s' not %s.": "Expected int for argument '%s' not %s.",
  "Expected string for argument '%s' not %s.": "Expected string for argument '%s' not %s.",
  "Expected bool for argument '%s' not %s.": "Expected bool for argument '%s' not %s.",
  "Expected DataType for argument '%s' not %s.": "Expected DataType for argument '%s' not %s.",
  "Error converting %s to a TensorShape: %s.": "Error converting %s to a TensorShape: %s.",
  "Don't know how to convert %s to a TensorProto for argument '%s'.": "Don't know how to convert %s to a TensorProto for argument '%s'.",
  "Using symbolic output of a Keras layer during eager execution {}": "Using symbolic output of a Keras layer during eager execution {}",
  "Expected list arguments to be the same length: %d != %d (%r vs. %r).": "Expected list arguments to be the same length: %d != %d (%r vs. %r).",
  "Tangent {} was expected to be of shape {} but is instead of shape {}": "Tangent {} was expected to be of shape {} but is instead of shape {}",
  "Tensor {} was specified as a primal multiple times. This may indicate an error. If it was intended, please sum the corresponding tangents.": "Tensor {} was specified as a primal multiple times. This may indicate an error. If it was intended, please sum the corresponding tangents.",
  "Accumulator is already recording.": "Accumulator is already recording.",
  "Accumulator is not recording.": "Accumulator is not recording.",
  "Called jvp() without first tracing anything.": "Called jvp() without first tracing anything.",
  "Arguments to a tf.function must be Tensors, Variables, or hashable Python objects (or nested structures of these types).\nGot type: %s": "Arguments to a tf.function must be Tensors, Variables, or hashable Python objects (or nested structures of these types).\nGot type: %s",
  "Cannot find a common shape when LHS shape is None but RHS shape is not (or vice versa): %s vs. %s": "Cannot find a common shape when LHS shape is None but RHS shape is not (or vice versa): %s vs. %s",
  "Expected x to be a TensorShape but saw %s": "Expected x to be a TensorShape but saw %s",
  "Expected y to be a TensorShape but saw %s": "Expected y to be a TensorShape but saw %s",
  "Unsupported attribute type for %s with type %s": "Unsupported attribute type for %s with type %s",
  "Arguments and signature arguments do not match. got: %s, expected: %s ": "Arguments and signature arguments do not match. got: %s, expected: %s ",
  "Internal error: unexpectedly got forwardprop information in a class that does not support forwardprop.": "Internal error: unexpectedly got forwardprop information in a class that does not support forwardprop.",
  "Internal error: the forward graph had {} inputs, but we expected {} ({} inference inputs and {} input tangents)": "Internal error: the forward graph had {} inputs, but we expected {} ({} inference inputs and {} input tangents)",
  "Internal error: expected {} forward graph inputs, but found {}.": "Internal error: expected {} forward graph inputs, but found {}.",
  "Internal error: failed to map all backward graph captures to the forward graph. Incorrectly mapped: {}": "Internal error: failed to map all backward graph captures to the forward graph. Incorrectly mapped: {}",
  "Unexpectedly added new outputs to the forward function when building the backward function: {}": "Unexpectedly added new outputs to the forward function when building the backward function: {}",
  "{} takes {} positional arguments but {} were given": "{} takes {} positional arguments but {} were given",
  "{} missing required arguments: {}": "{} missing required arguments: {}",
  "{} got two values for argument '{}'": "{} got two values for argument '{}'",
  "{} got unexpected keyword arguments: {}.": "{} got unexpected keyword arguments: {}.",
  "{}: expected argument #{}(zero-based) to be a Tensor; got {} ({})": "{}: expected argument #{}(zero-based) to be a Tensor; got {} ({})",
  "{} got unexpected keyword arguments: {}": "{} got unexpected keyword arguments: {}",
  "{}: argument {} had incorrect type\n  expected: {}\n       got: {}": "{}: argument {} had incorrect type\n  expected: {}\n       got: {}",
  "{} expected a Tensor in {}, but got {} value {}": "{} expected a Tensor in {}, but got {} value {}",
  "ConcreteFunction {} was constructed with {} value {} in {}, but was called with {} value {}": "ConcreteFunction {} was constructed with {} value {} in {}, but was called with {} value {}",
  "The argument {} (value {}) is not compatible with the shape this function was traced with. Expected shape {}, but got shape {}.\n\nIf you called get_concrete_function, you may need to pass a tf.TensorSpec(..., shape=...) with a less specific shape, having None on axes which can vary.": "The argument {} (value {}) is not compatible with the shape this function was traced with. Expected shape {}, but got shape {}.\n\nIf you called get_concrete_function, you may need to pass a tf.TensorSpec(..., shape=...) with a less specific shape, having None on axes which can vary.",
  "All inputs to `ConcreteFunction`s must be Tensors; on invocation of %s, the %d-th input (%s) was not a Tensor.": "All inputs to `ConcreteFunction`s must be Tensors; on invocation of %s, the %d-th input (%s) was not a Tensor.",
  "Cannot define a TensorFlow function from a Python function with keyword-only arguments when input_signature is provided.": "Cannot define a TensorFlow function from a Python function with keyword-only arguments when input_signature is provided.",
  "input_signature must be either a tuple or a list, received ": "input_signature must be either a tuple or a list, received ",
  "weakref input {} not supported for function {}": "weakref input {} not supported for function {}",
  "{} takes {} positional arguments (as specified by the input_signature) but {} were given": "{} takes {} positional arguments (as specified by the input_signature) but {} were given",
  "{} got unexpected keyword argument `{}`": "{} got unexpected keyword argument `{}`",
  "{} got keyword argument `{}` that was not included in input_signature": "{} got keyword argument `{}` that was not included in input_signature",
  "{} missing 1 required argument: {}": "{} missing 1 required argument: {}",
  "{} got unexpected keyword arguments: {}\n(Cannot define a TensorFlow function from a Python function with keyword arguments when input_signature is provided.)": "{} got unexpected keyword arguments: {}\n(Cannot define a TensorFlow function from a Python function with keyword arguments when input_signature is provided.)",
  "The output of __array__ must be an np.ndarray (got {} from {}).": "The output of __array__ must be an np.ndarray (got {} from {}).",
  "Structure of Python function inputs does not match input_signature:\n%s": "Structure of Python function inputs does not match input_signature:\n%s",
  "When input_signature is provided, all inputs to the Python function must be convertible to tensors:\n%s": "When input_signature is provided, all inputs to the Python function must be convertible to tensors:\n%s",
  "Python inputs incompatible with input_signature:\n%s": "Python inputs incompatible with input_signature:\n%s",
  "Cannot define a TensorFlow function from a Python function with keyword arguments when input_signature is provided.": "Cannot define a TensorFlow function from a Python function with keyword arguments when input_signature is provided.",
  "Structure of Python function inputs does not match input_signature.": "Structure of Python function inputs does not match input_signature.",
  "When input_signature is provided, all inputs to the Python function must be Tensors, Variables, tf.TensorSpec or tf.VariableSpec objects.": "When input_signature is provided, all inputs to the Python function must be Tensors, Variables, tf.TensorSpec or tf.VariableSpec objects.",
  "Python inputs incompatible with input_signature: inputs (%s), input_signature (%s)": "Python inputs incompatible with input_signature: inputs (%s), input_signature (%s)",
  "Expected arg_specs len to match relaxed_arg_specs len: %d vs. %d": "Expected arg_specs len to match relaxed_arg_specs len: %d vs. %d",
  "Arguments supplied to `defun`-generated functions must be hashable.  Original error: %s": "Arguments supplied to `defun`-generated functions must be hashable.  Original error: %s",
  "Only defun function is allowed to be registered. Got type: %s": "Only defun function is allowed to be registered. Got type: %s",
  "Invalid input_signature {}; input_signature must be a possibly nested sequence of TensorSpec objects.": "Invalid input_signature {}; input_signature must be a possibly nested sequence of TensorSpec objects.",
  "Unknown value for unconnected_gradients: %r": "Unknown value for unconnected_gradients: %r",
  "Could not copy source node {} because it has inputs.": "Could not copy source node {} because it has inputs.",
  "Cannot create {} metric with label >= {}": "Cannot create {} metric with label >= {}",
  "The {} expects taking {} labels": "The {} expects taking {} labels",
  "Another profiler is running.": "Another profiler is running.",
  "Cannot stop profiling. No profiler is running.": "Cannot stop profiling. No profiler is running.",
  "Must provide at least one remote_host": "Must provide at least one remote_host",
  "`tf.config.experimental_connect_to_cluster` can only be called in eager mode.": "`tf.config.experimental_connect_to_cluster` can only be called in eager mode.",
  "`cluster_spec_or_resolver` must be a `ClusterSpec` or a `ClusterResolver`.": "`cluster_spec_or_resolver` must be a `ClusterSpec` or a `ClusterResolver`.",
  "`cluster_device_filters` must be an instance of `tf.train.experimental.ClusterDeviceFilters`.": "`cluster_device_filters` must be an instance of `tf.train.experimental.ClusterDeviceFilters`.",
  "`make_master_device_default` is set to True but cannot find master %s in the cluster": "`make_master_device_default` is set to True but cannot find master %s in the cluster",
  "`connect_to_cluster` is called inside existing device scope %s, which is different from the master device scope %s to enter. This is not allowed.": "`connect_to_cluster` is called inside existing device scope %s, which is different from the master device scope %s to enter. This is not allowed.",
  "Invalid TensorInfo.encoding: %s": "Invalid TensorInfo.encoding: %s",
  "Keyword arguments not supported when calling a wrap_function-decorated function.": "Keyword arguments not supported when calling a wrap_function-decorated function.",
  "Feeds must be tensors.": "Feeds must be tensors.",
  "Can only prune function whose feeds and fetches are from this graph (%s). Input %s is from graph %s": "Can only prune function whose feeds and fetches are from this graph (%s). Input %s is from graph %s",
  "Items of feature_columns must be a _DenseColumn. You can wrap a categorical column with an embedding_column or indicator_column. Given: {}": "Items of feature_columns must be a _DenseColumn. You can wrap a categorical column with an embedding_column or indicator_column. Given: {}",
  "Items of feature_columns must be either a _DenseColumn or _CategoricalColumn. Given: {}": "Items of feature_columns must be either a _DenseColumn or _CategoricalColumn. Given: {}",
  "All feature_columns must be _FeatureColumn instances. Given: {}": "All feature_columns must be _FeatureColumn instances. Given: {}",
  "feature_columns contain different parse_spec for key {}. Given {} and {}": "feature_columns contain different parse_spec for key {}. Given {} and {}",
  "Invalid dimension {}.": "Invalid dimension {}.",
  "Must specify both `ckpt_to_load_from` and `tensor_name_in_ckpt` or none of them.": "Must specify both `ckpt_to_load_from` and `tensor_name_in_ckpt` or none of them.",
  "initializer must be callable if specified. Embedding of column_name: {}": "initializer must be callable if specified. Embedding of column_name: {}",
  "dtype must be convertible to float. dtype: {}, key: {}": "dtype must be convertible to float. dtype: {}, key: {}",
  "normalizer_fn must be a callable. Given: {}": "normalizer_fn must be a callable. Given: {}",
  "source_column must be a column generated with numeric_column(). Given: {}": "source_column must be a column generated with numeric_column(). Given: {}",
  "source_column must be one-dimensional column. Given: {}": "source_column must be one-dimensional column. Given: {}",
  "boundaries must be a sorted list.": "boundaries must be a sorted list.",
  "hash_bucket_size must be set. key: {}": "hash_bucket_size must be set. key: {}",
  "hash_bucket_size must be at least 1. hash_bucket_size: {}, key: {}": "hash_bucket_size must be at least 1. hash_bucket_size: {}, key: {}",
  "Missing vocabulary_file in {}.": "Missing vocabulary_file in {}.",
  "vocabulary_file in {} does not exist.": "vocabulary_file in {} does not exist.",
  "Invalid vocabulary_size in {}.": "Invalid vocabulary_size in {}.",
  "Can't specify both num_oov_buckets and default_value in {}.": "Can't specify both num_oov_buckets and default_value in {}.",
  "Invalid num_oov_buckets {} in {}.": "Invalid num_oov_buckets {} in {}.",
  "vocabulary_list {} must be non-empty, column_name: {}": "vocabulary_list {} must be non-empty, column_name: {}",
  "Duplicate keys in vocabulary_list {}, column_name: {}": "Duplicate keys in vocabulary_list {}, column_name: {}",
  "dtype {} and vocabulary dtype {} do not match, column_name: {}": "dtype {} and vocabulary dtype {} do not match, column_name: {}",
  "num_buckets {} < 1, column_name {}": "num_buckets {} < 1, column_name {}",
  "default_value {} not in range [0, {}), column_name {}": "default_value {} not in range [0, {}), column_name {}",
  "dtype {} is not convertible to float.": "dtype {} is not convertible to float.",
  "hash_bucket_size must be > 1. hash_bucket_size: {}": "hash_bucket_size must be > 1. hash_bucket_size: {}",
  "keys must be a list with length > 1. Given: {}": "keys must be a list with length > 1. Given: {}",
  "Unsupported key type. All keys must be either string, or categorical column except _HashedCategoricalColumn. Given: {}": "Unsupported key type. All keys must be either string, or categorical column except _HashedCategoricalColumn. Given: {}",
  "categorical_column_with_hash_bucket is not supported for crossing. Hashing before crossing will increase probability of collision. Instead, use the feature name as a string. Given: {}": "categorical_column_with_hash_bucket is not supported for crossing. Hashing before crossing will increase probability of collision. Instead, use the feature name as a string. Given: {}",
  "Feature {} is not in features dictionary.": "Feature {} is not in features dictionary.",
  "\"key\" must be either a \"str\" or \"_FeatureColumn\". Provided: {}": "\"key\" must be either a \"str\" or \"_FeatureColumn\". Provided: {}",
  "Column {} is not supported.": "Column {} is not supported.",
  "Feature (key: {}) cannot have rank 0. Given: {}": "Feature (key: {}) cannot have rank 0. Given: {}",
  "Expected feature_columns to be iterable, found dict.": "Expected feature_columns to be iterable, found dict.",
  "Items of feature_columns must be a _FeatureColumn. Given (type {}): {}.": "Items of feature_columns must be a _FeatureColumn. Given (type {}): {}.",
  "feature_columns must not be empty.": "feature_columns must not be empty.",
  "Duplicate feature column name found for columns: {} and {}. This usually means that these columns refer to same base feature. Either one must be discarded or a duplicated but renamed item must be inserted in features dict.": "Duplicate feature column name found for columns: {} and {}. This usually means that these columns refer to same base feature. Either one must be discarded or a duplicated but renamed item must be inserted in features dict.",
  "The corresponding Tensor of numerical column must be a Tensor. SparseTensor is not supported. key: {}": "The corresponding Tensor of numerical column must be a Tensor. SparseTensor is not supported. key: {}",
  "In embedding_column: {}. categorical_column must not be of type _SequenceCategoricalColumn. Suggested fix A: If you wish to use input_layer, use a non-sequence categorical_column_with_*. Suggested fix B: If you wish to create sequence input, use sequence_input_layer instead of input_layer. Given (type {}): {}": "In embedding_column: {}. categorical_column must not be of type _SequenceCategoricalColumn. Suggested fix A: If you wish to use input_layer, use a non-sequence categorical_column_with_*. Suggested fix B: If you wish to create sequence input, use sequence_input_layer instead of input_layer. Given (type {}): {}",
  "In embedding_column: {}. categorical_column must be of type _SequenceCategoricalColumn to use sequence_input_layer. Suggested fix: Use one of sequence_categorical_column_with_*. Given (type {}): {}": "In embedding_column: {}. categorical_column must be of type _SequenceCategoricalColumn to use sequence_input_layer. Suggested fix: Use one of sequence_categorical_column_with_*. Given (type {}): {}",
  "Collection {} can only contain one variable. Suggested fix A: Choose a unique name for this collection. Suggested fix B: Do not add any variables to this collection. The feature_column library already adds a variable under the hood.": "Collection {} can only contain one variable. Suggested fix A: Choose a unique name for this collection. Suggested fix B: Do not add any variables to this collection. The feature_column library already adds a variable under the hood.",
  "Shared embedding collection {} contains variable {} of unexpected shape {}. Expected shape is {}. Suggested fix A: Choose a unique name for this collection. Suggested fix B: Do not add any variables to this collection. The feature_column library already adds a variable under the hood.": "Shared embedding collection {} contains variable {} of unexpected shape {}. Expected shape is {}. Suggested fix A: Choose a unique name for this collection. Suggested fix B: Do not add any variables to this collection. The feature_column library already adds a variable under the hood.",
  "shape dimensions must be integer. shape: {}, key: {}": "shape dimensions must be integer. shape: {}, key: {}",
  "shape dimensions must be greater than 0. shape: {}, key: {}": "shape dimensions must be greater than 0. shape: {}, key: {}",
  "SparseColumn input must be a SparseTensor.": "SparseColumn input must be a SparseTensor.",
  "Column dtype and SparseTensors dtype must be compatible. key: {}, column dtype: {}, tensor dtype: {}": "Column dtype and SparseTensors dtype must be compatible. key: {}, column dtype: {}, tensor dtype: {}",
  "Invalid input, not integer. key: {} dtype: {}": "Invalid input, not integer. key: {} dtype: {}",
  "Parse config {} already exists for {}.": "Parse config {} already exists for {}.",
  "Missing weights {}.": "Missing weights {}.",
  "Bad dtype, expected {}, but got {}.": "Bad dtype, expected {}, but got {}.",
  "crossed_column does not support weight_tensor, but the given column populates weight_tensor. Given column: {}": "crossed_column does not support weight_tensor, but the given column populates weight_tensor. Given column: {}",
  "Unsupported column type. Given: {}": "Unsupported column type. Given: {}",
  "Batch size (first dimension) of each feature must be same. Batch size of columns ({}, {}): ({}, {})": "Batch size (first dimension) of each feature must be same. Batch size of columns ({}, {}): ({}, {})",
  "Variable already exists.": "Variable already exists.",
  "Variable does not exist.": "Variable does not exist.",
  "Resource does not exist.": "Resource does not exist.",
  "All feature_columns must be FeatureColumn instances. Given: {}": "All feature_columns must be FeatureColumn instances. Given: {}",
  "shared_embedding_columns are not supported when eager execution is enabled.": "shared_embedding_columns are not supported when eager execution is enabled.",
  "initializer must be callable if specified.": "initializer must be callable if specified.",
  "All categorical_columns must be subclasses of _CategoricalColumn. Given: {}, of type: {}": "All categorical_columns must be subclasses of _CategoricalColumn. Given: {}, of type: {}",
  "To use shared_embedding_column, all categorical_columns must have the same type, or be weighted_categorical_column or sequence column of the same type. Given column: {} of type: {} does not match given column: {} of type: {}": "To use shared_embedding_column, all categorical_columns must have the same type, or be weighted_categorical_column or sequence column of the same type. Given column: {} of type: {} does not match given column: {} of type: {}",
  "To use shared_embedding_column, all categorical_columns must have the same number of buckets. ven column: {} with buckets: {} does  not match column: {} with buckets: {}": "To use shared_embedding_column, all categorical_columns must have the same number of buckets. ven column: {} with buckets: {} does  not match column: {} with buckets: {}",
  "All categorical_columns must be subclasses of CategoricalColumn. Given: {}, of type: {}": "All categorical_columns must be subclasses of CategoricalColumn. Given: {}, of type: {}",
  "boundaries must not be empty.": "boundaries must not be empty.",
  "Unsupported input type. Input must be a CategoricalColumn. Given: {}": "Unsupported input type. Input must be a CategoricalColumn. Given: {}",
  "\"key\" must be either a \"str\" or \"FeatureColumn\". Provided: {}": "\"key\" must be either a \"str\" or \"FeatureColumn\". Provided: {}",
  "SharedEmbeddingColumns are not supported in `linear_model` or `input_layer`. Please use `DenseFeatures` or `LinearModel` instead.": "SharedEmbeddingColumns are not supported in `linear_model` or `input_layer`. Please use `DenseFeatures` or `LinearModel` instead.",
  "Graph changed while trying to add control dependencies.": "Graph changed while trying to add control dependencies.",
  "%s not in list": "%s not in list",
  "No entry found for ": "No entry found for ",

}